{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, Embedding\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/eng-katakana.csv', header=None, names=['eng', 'katakana'])\n",
    "data = data.sample(frac=1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>katakana</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11206</th>\n",
       "      <td>Dorogobuzh</td>\n",
       "      <td>ドロゴブージ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80376</th>\n",
       "      <td>Gail Hopkins</td>\n",
       "      <td>ゲイル・ホプキンス</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38108</th>\n",
       "      <td>Novatek</td>\n",
       "      <td>ノヴァテク</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29960</th>\n",
       "      <td>Gyula Cseszneky</td>\n",
       "      <td>チェスネキー・ジュラ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22295</th>\n",
       "      <td>Occhieppo Superiore</td>\n",
       "      <td>オッキエッポ・スペリオーレ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       eng       katakana\n",
       "11206           Dorogobuzh         ドロゴブージ\n",
       "80376         Gail Hopkins      ゲイル・ホプキンス\n",
       "38108              Novatek          ノヴァテク\n",
       "29960      Gyula Cseszneky     チェスネキー・ジュラ\n",
       "22295  Occhieppo Superiore  オッキエッポ・スペリオーレ"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dorogobuzh', 'gail hopkins', 'novatek']\n",
      "['ドロゴブージ', 'ゲイル・ホプキンス', 'ノヴァテク']\n"
     ]
    }
   ],
   "source": [
    "input_texts = [s.lower() for s in data['eng']]\n",
    "target_texts = [s for s in data['katakana']]\n",
    "\n",
    "print(input_texts[0:3])\n",
    "print(target_texts[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75082\n",
      "32179\n"
     ]
    }
   ],
   "source": [
    "# Split train and test\n",
    "training_rate = 0.7\n",
    "train_len = int(len(data) * training_rate)\n",
    "training_input = data_input[:train_len]\n",
    "training_output = data_output[:train_len]\n",
    "validation_input = data_input[train_len:]\n",
    "validation_output = data_output[train_len:]\n",
    "\n",
    "print(len(training_input))\n",
    "print(len(validation_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding character input\n",
    "\n",
    "We will create a character dictionary and encode the title from a string (a sequence of character) into a sequence of IDs. We will also create the reverse dictionary that will be used for getting the result later.\n",
    "\n",
    "Note that in practice, we must not build the dictionary from all data (`data_input` and `data_output`), but only use the training set (`training_input` and `training_output`). We also have to handle out-of-dictionary characters. However, for now, I will skip that part.\n",
    "\n",
    "Note:\n",
    "- We will use 0 for padding and 1 for 'START'. So, `count` starts from 2. \n",
    "- This is to take advantage of `mask_zero=True` feature for Embedding Layer in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English character dict size: 54\n",
      "Katakana character dict size: 89\n",
      "{'a': 2, '5': 3, '2': 4, 'g': 5, 'h': 6, 't': 7, 'ó': 8, '4': 9, 'ò': 10, 'þ': 11, 'p': 12, 'ľ': 13, 'ü': 14, '7': 15, ' ': 16, 'ù': 17, 'r': 18, 's': 19, 'v': 20, 'c': 21, 'ž': 22, 'x': 23, 'n': 24, 'ý': 25, 'ź': 26, 'o': 27, 'k': 28, '0': 29, 'õ': 30, 'w': 31, 'e': 32, 'q': 33, 'ż': 34, '1': 35, '6': 36, 'ú': 37, 'ê': 38, 'j': 39, 'f': 40, 'ŵ': 41, '8': 42, 'l': 43, 'd': 44, '9': 45, 'u': 46, 'b': 47, 'm': 48, 'i': 49, 'z': 50, 'y': 51, '3': 52, 'ļ': 53}\n",
      "{1: 'START', 2: 'a', 3: '5', 4: '2', 5: 'g', 6: 'h', 7: 't', 8: 'ó', 9: '4', 10: 'ò', 11: 'þ', 12: 'p', 13: 'ľ', 14: 'ü', 15: '7', 16: ' ', 17: 'ù', 18: 'r', 19: 's', 20: 'v', 21: 'c', 22: 'ž', 23: 'x', 24: 'n', 25: 'ý', 26: 'ź', 27: 'o', 28: 'k', 29: '0', 30: 'õ', 31: 'w', 32: 'e', 33: 'q', 34: 'ż', 35: '1', 36: '6', 37: 'ú', 38: 'ê', 39: 'j', 40: 'f', 41: 'ŵ', 42: '8', 43: 'l', 44: 'd', 45: '9', 46: 'u', 47: 'b', 48: 'm', 49: 'i', 50: 'z', 51: 'y', 52: '3', 53: 'ļ'}\n"
     ]
    }
   ],
   "source": [
    "START_CHAR_CODE = 1\n",
    "\n",
    "def encode_characters(titles):\n",
    "    count = 2\n",
    "    encoding = {}\n",
    "    decoding = {1: 'START'}\n",
    "    for c in set([c for title in titles for c in title]):\n",
    "        encoding[c] = count\n",
    "        decoding[count] = c\n",
    "        count += 1\n",
    "    return encoding, decoding, count\n",
    "\n",
    "\n",
    "input_encoding, input_decoding, input_dict_size = encode_characters(data_input)\n",
    "output_encoding, output_decoding, output_dict_size = encode_characters(data_output)\n",
    "\n",
    "\n",
    "print('English character dict size:', input_dict_size)\n",
    "print('Katakana character dict size:', output_dict_size)\n",
    "\n",
    "print(input_encoding)\n",
    "print(input_decoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming the titles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input [[44. 27. 18. ...  0.  0.  0.]\n",
      " [ 5.  2. 49. ...  0.  0.  0.]\n",
      " [24. 27. 20. ...  0.  0.  0.]\n",
      " ...\n",
      " [39. 27.  6. ...  0.  0.  0.]\n",
      " [ 5. 24.  2. ...  0.  0.  0.]\n",
      " [32.  6. 18. ...  0.  0.  0.]]\n",
      "output [[26. 50. 15. ...  0.  0.  0.]\n",
      " [11. 32.  9. ...  0.  0.  0.]\n",
      " [84. 56. 69. ...  0.  0.  0.]\n",
      " ...\n",
      " [24. 25. 20. ...  0.  0.  0.]\n",
      " [54. 66.  8. ...  0.  0.  0.]\n",
      " [37. 40. 72. ...  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "def transform(encoding, data, vector_size):\n",
    "    transformed_data = np.zeros(shape=(len(data), vector_size))\n",
    "    for i in range(len(data)):\n",
    "        for j in range(min(len(data[i]), vector_size)):\n",
    "            transformed_data[i][j] = encoding[data[i][j]]\n",
    "    return transformed_data\n",
    "\n",
    "INPUT_LENGTH = 20\n",
    "OUTPUT_LENGTH = 20\n",
    "\n",
    "encoded_training_input = transform(input_encoding, training_input, vector_size=INPUT_LENGTH)\n",
    "encoded_training_output = transform(output_encoding, training_output, vector_size=OUTPUT_LENGTH)\n",
    "encoded_validation_input = transform(input_encoding, validation_input, vector_size=INPUT_LENGTH)\n",
    "encoded_validation_output = transform(output_encoding, validation_output, vector_size=OUTPUT_LENGTH)\n",
    "\n",
    "print('input', encoded_training_input)\n",
    "print('output', encoded_training_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder input [[44. 27. 18. 27.  5. 27. 47. 46. 50.  6.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]]\n",
      "decoder input [[ 1. 26. 50. 15. 68. 59. 24.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]]\n",
      "decoder output [[26 50 15 68 59 24  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "decoder output (one-hot) [[[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "# Encoder Input\n",
    "training_encoder_input = encoded_training_input\n",
    "\n",
    "# Decoder Input (need padding py START_CHAR_CODE)\n",
    "training_decoder_input = np.zeros_like(encoded_training_output)\n",
    "training_decoder_input[:, 1:] = encoded_training_output[:,:-1] # offset one timestpe\n",
    "training_decoder_input[:, 0] = START_CHAR_CODE # first timestep is 1, means START\n",
    "\n",
    "# Decoder Output (one-hot encode)\n",
    "training_decoder_output = np.eye(output_dict_size)[encoded_training_output.astype('int')]\n",
    "\n",
    "print('encoder input', training_encoder_input[:1])\n",
    "print('decoder input', training_decoder_input[:1])\n",
    "print('decoder output', training_decoder_output[:1].argmax(axis=2))\n",
    "print('decoder output (one-hot)', training_decoder_output[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_encoder_input = encoded_validation_input\n",
    "validation_decoder_input = np.zeros_like(encoded_validation_output)\n",
    "validation_decoder_input[:, 1:] = encoded_validation_output[:,:-1]\n",
    "validation_decoder_input[:, 0] = START_CHAR_CODE\n",
    "validation_decoder_output = np.eye(output_dict_size)[encoded_validation_output.astype('int')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence-to-Sequence in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64  # Batch size for training.\n",
    "epochs = 100  # Number of epochs to train for.\n",
    "latent_dim = 64  # Latent dimensionality of the encoding space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 20)\n",
      "(?, 20, 64)\n",
      "(?, 64)\n",
      "(?, 64)\n"
     ]
    }
   ],
   "source": [
    "encoder_input = Input(shape=(INPUT_LENGTH,))\n",
    "print(encoder_input.shape)\n",
    "encoder = Embedding(input_dict_size, 64, input_length=INPUT_LENGTH, mask_zero=True)(encoder_input)\n",
    "print(encoder.shape)\n",
    "encoder_outputs, state_h, state_c = LSTM(latent_dim, return_state=True)(encoder)\n",
    "print(state_h.shape)\n",
    "print(state_c.shape)\n",
    "\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 20)\n",
      "(?, 20, 64)\n",
      "(?, ?, 64)\n",
      "(?, 20, 89)\n"
     ]
    }
   ],
   "source": [
    "decoder_input = Input(shape=(OUTPUT_LENGTH,))\n",
    "print(decoder_input.shape)\n",
    "decoder = Embedding(output_dict_size, 64, input_length=OUTPUT_LENGTH, mask_zero=True)(decoder_input)\n",
    "print(decoder.shape)\n",
    "\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder,\n",
    "                                     initial_state=encoder_states)\n",
    "print(decoder_outputs.shape)\n",
    "\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "print(decoder_outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_input, decoder_input], decoder_outputs)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 66822 samples, validate on 8260 samples\n",
      "Epoch 1/2\n",
      "66822/66822 [==============================] - 67s 1ms/step - loss: 1.3288 - val_loss: 1.3557\n",
      "Epoch 2/2\n",
      "66822/66822 [==============================] - 63s 946us/step - loss: 1.2873 - val_loss: 1.3530\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1827a74518>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earlystopper = EarlyStopping(monitor='val_loss', patience=3, verbose=1)\n",
    "\n",
    "model.fit(x=[training_encoder_input, training_decoder_input], y=[training_decoder_output],\n",
    "      validation_split=0.11,\n",
    "      verbose=1,\n",
    "      batch_size=64,\n",
    "      epochs=2,\n",
    "      callbacks=[earlystopper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(text):\n",
    "    encoder_input = transform(input_encoding, [text.lower()], 20)\n",
    "    decoder_input = np.zeros(shape=(len(encoder_input), OUTPUT_LENGTH))\n",
    "    decoder_input[:,0] = START_CHAR_CODE\n",
    "    for i in range(1, OUTPUT_LENGTH):\n",
    "        output = model.predict([encoder_input, decoder_input]).argmax(axis=2)\n",
    "        decoder_input[:,i] = output[:,i]\n",
    "    return decoder_input[:,1:]\n",
    "\n",
    "def decode(decoding, sequence):\n",
    "    text = ''\n",
    "    for i in sequence:\n",
    "        if i == 0:\n",
    "            break\n",
    "        text += output_decoding[i]\n",
    "    return text\n",
    "\n",
    "def to_katakana(text):\n",
    "    decoder_output = generate(text)\n",
    "    return decode(output_decoding, decoder_output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "James ジャメス\n",
      "John ジョン\n",
      "Robert ロベルト\n",
      "Mary マリー\n",
      "Patricia パトリカイ\n",
      "Linda リンダ\n"
     ]
    }
   ],
   "source": [
    "common_american_names = ['James', 'John', 'Robert', 'Mary', 'Patricia', 'Linda']\n",
    "for name in common_american_names:\n",
    "    print(name, to_katakana(name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
