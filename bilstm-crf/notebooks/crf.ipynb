{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/ner_dataset.csv', encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS Tag\n",
       "0  Sentence: 1      Thousands  NNS   O\n",
       "1          NaN             of   IN   O\n",
       "2          NaN  demonstrators  NNS   O\n",
       "3          NaN           have  VBP   O\n",
       "4          NaN        marched  VBN   O"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS Tag\n",
       "0  Sentence: 1      Thousands  NNS   O\n",
       "1  Sentence: 1             of   IN   O\n",
       "2  Sentence: 1  demonstrators  NNS   O\n",
       "3  Sentence: 1           have  VBP   O\n",
       "4  Sentence: 1        marched  VBN   O"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fill NaN\n",
    "data = data.fillna(method='ffill')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1048565</th>\n",
       "      <td>Sentence: 47958</td>\n",
       "      <td>impact</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048566</th>\n",
       "      <td>Sentence: 47958</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048567</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>Indian</td>\n",
       "      <td>JJ</td>\n",
       "      <td>B-gpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048568</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>forces</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048569</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>said</td>\n",
       "      <td>VBD</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048570</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>they</td>\n",
       "      <td>PRP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048571</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>responded</td>\n",
       "      <td>VBD</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048572</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048573</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048574</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>attack</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Sentence #       Word  POS    Tag\n",
       "1048565  Sentence: 47958     impact   NN      O\n",
       "1048566  Sentence: 47958          .    .      O\n",
       "1048567  Sentence: 47959     Indian   JJ  B-gpe\n",
       "1048568  Sentence: 47959     forces  NNS      O\n",
       "1048569  Sentence: 47959       said  VBD      O\n",
       "1048570  Sentence: 47959       they  PRP      O\n",
       "1048571  Sentence: 47959  responded  VBD      O\n",
       "1048572  Sentence: 47959         to   TO      O\n",
       "1048573  Sentence: 47959        the   DT      O\n",
       "1048574  Sentence: 47959     attack   NN      O"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essential info about entities:\n",
    "\n",
    "    geo = Geographical Entity\n",
    "    org = Organization\n",
    "    per = Person\n",
    "    gpe = Geopolitical Entity\n",
    "    tim = Time indicator\n",
    "    art = Artifact\n",
    "    eve = Event\n",
    "    nat = Natural Phenomenon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "O        887908\n",
       "B-geo     37644\n",
       "B-tim     20333\n",
       "B-org     20143\n",
       "I-per     17251\n",
       "B-per     16990\n",
       "I-org     16784\n",
       "B-gpe     15870\n",
       "I-geo      7414\n",
       "I-tim      6528\n",
       "B-art       402\n",
       "B-eve       308\n",
       "I-art       297\n",
       "I-eve       253\n",
       "B-nat       201\n",
       "I-gpe       198\n",
       "I-nat        51\n",
       "Name: Tag, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Tag.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['operates',\n",
       " 'extra',\n",
       " 'Lennon',\n",
       " 'Cindy',\n",
       " 'Melanesians',\n",
       " 'cease',\n",
       " 'crept',\n",
       " 'Gaule',\n",
       " 'wafted',\n",
       " 'continent']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = list(set(data['Word'].values))\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35178"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_words = len(words)\n",
    "n_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have 47959 sentences containing 35178 different words. We change the SentenceGetter class from last post a little and use it to retrieve sentences with their labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceGetter(object):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, p, t) for w, p, t in zip(s[\"Word\"].values.tolist(),\n",
    "                                                           s[\"POS\"].values.tolist(),\n",
    "                                                           s[\"Tag\"].values.tolist())]\n",
    "        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "    \n",
    "    def get_next(self):\n",
    "        try:\n",
    "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s\n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "getter = SentenceGetter(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = getter.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Thousands', 'NNS', 'O'),\n",
       " ('of', 'IN', 'O'),\n",
       " ('demonstrators', 'NNS', 'O'),\n",
       " ('have', 'VBP', 'O'),\n",
       " ('marched', 'VBN', 'O'),\n",
       " ('through', 'IN', 'O'),\n",
       " ('London', 'NNP', 'B-geo'),\n",
       " ('to', 'TO', 'O'),\n",
       " ('protest', 'VB', 'O'),\n",
       " ('the', 'DT', 'O'),\n",
       " ('war', 'NN', 'O'),\n",
       " ('in', 'IN', 'O'),\n",
       " ('Iraq', 'NNP', 'B-geo'),\n",
       " ('and', 'CC', 'O'),\n",
       " ('demand', 'VB', 'O'),\n",
       " ('the', 'DT', 'O'),\n",
       " ('withdrawal', 'NN', 'O'),\n",
       " ('of', 'IN', 'O'),\n",
       " ('British', 'JJ', 'B-gpe'),\n",
       " ('troops', 'NNS', 'O'),\n",
       " ('from', 'IN', 'O'),\n",
       " ('that', 'DT', 'O'),\n",
       " ('country', 'NN', 'O'),\n",
       " ('.', '.', 'O')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all sentences\n",
    "sentences = getter.sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we craft a set of features and prepare the dataset. [feature formats](https://sklearn-crfsuite.readthedocs.io/en/latest/tutorial.html#features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2],\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [sent2features(s) for s in sentences]\n",
    "y = [sent2labels(s) for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'+1:postag': 'IN',\n",
       "  '+1:postag[:2]': 'IN',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:word.lower()': 'of',\n",
       "  'BOS': True,\n",
       "  'bias': 1.0,\n",
       "  'postag': 'NNS',\n",
       "  'postag[:2]': 'NN',\n",
       "  'word.isdigit()': False,\n",
       "  'word.istitle()': True,\n",
       "  'word.isupper()': False,\n",
       "  'word.lower()': 'thousands',\n",
       "  'word[-2:]': 'ds',\n",
       "  'word[-3:]': 'nds'},\n",
       " {'+1:postag': 'NNS',\n",
       "  '+1:postag[:2]': 'NN',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:word.lower()': 'demonstrators',\n",
       "  '-1:postag': 'NNS',\n",
       "  '-1:postag[:2]': 'NN',\n",
       "  '-1:word.istitle()': True,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:word.lower()': 'thousands',\n",
       "  'bias': 1.0,\n",
       "  'postag': 'IN',\n",
       "  'postag[:2]': 'IN',\n",
       "  'word.isdigit()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isupper()': False,\n",
       "  'word.lower()': 'of',\n",
       "  'word[-2:]': 'of',\n",
       "  'word[-3:]': 'of'},\n",
       " {'+1:postag': 'VBP',\n",
       "  '+1:postag[:2]': 'VB',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:word.lower()': 'have',\n",
       "  '-1:postag': 'IN',\n",
       "  '-1:postag[:2]': 'IN',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:word.lower()': 'of',\n",
       "  'bias': 1.0,\n",
       "  'postag': 'NNS',\n",
       "  'postag[:2]': 'NN',\n",
       "  'word.isdigit()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isupper()': False,\n",
       "  'word.lower()': 'demonstrators',\n",
       "  'word[-2:]': 'rs',\n",
       "  'word[-3:]': 'ors'},\n",
       " {'+1:postag': 'VBN',\n",
       "  '+1:postag[:2]': 'VB',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:word.lower()': 'marched',\n",
       "  '-1:postag': 'NNS',\n",
       "  '-1:postag[:2]': 'NN',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:word.lower()': 'demonstrators',\n",
       "  'bias': 1.0,\n",
       "  'postag': 'VBP',\n",
       "  'postag[:2]': 'VB',\n",
       "  'word.isdigit()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isupper()': False,\n",
       "  'word.lower()': 'have',\n",
       "  'word[-2:]': 've',\n",
       "  'word[-3:]': 'ave'},\n",
       " {'+1:postag': 'IN',\n",
       "  '+1:postag[:2]': 'IN',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:word.lower()': 'through',\n",
       "  '-1:postag': 'VBP',\n",
       "  '-1:postag[:2]': 'VB',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:word.lower()': 'have',\n",
       "  'bias': 1.0,\n",
       "  'postag': 'VBN',\n",
       "  'postag[:2]': 'VB',\n",
       "  'word.isdigit()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isupper()': False,\n",
       "  'word.lower()': 'marched',\n",
       "  'word[-2:]': 'ed',\n",
       "  'word[-3:]': 'hed'},\n",
       " {'+1:postag': 'NNP',\n",
       "  '+1:postag[:2]': 'NN',\n",
       "  '+1:word.istitle()': True,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:word.lower()': 'london',\n",
       "  '-1:postag': 'VBN',\n",
       "  '-1:postag[:2]': 'VB',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:word.lower()': 'marched',\n",
       "  'bias': 1.0,\n",
       "  'postag': 'IN',\n",
       "  'postag[:2]': 'IN',\n",
       "  'word.isdigit()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isupper()': False,\n",
       "  'word.lower()': 'through',\n",
       "  'word[-2:]': 'gh',\n",
       "  'word[-3:]': 'ugh'},\n",
       " {'+1:postag': 'TO',\n",
       "  '+1:postag[:2]': 'TO',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:word.lower()': 'to',\n",
       "  '-1:postag': 'IN',\n",
       "  '-1:postag[:2]': 'IN',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:word.lower()': 'through',\n",
       "  'bias': 1.0,\n",
       "  'postag': 'NNP',\n",
       "  'postag[:2]': 'NN',\n",
       "  'word.isdigit()': False,\n",
       "  'word.istitle()': True,\n",
       "  'word.isupper()': False,\n",
       "  'word.lower()': 'london',\n",
       "  'word[-2:]': 'on',\n",
       "  'word[-3:]': 'don'},\n",
       " {'+1:postag': 'VB',\n",
       "  '+1:postag[:2]': 'VB',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:word.lower()': 'protest',\n",
       "  '-1:postag': 'NNP',\n",
       "  '-1:postag[:2]': 'NN',\n",
       "  '-1:word.istitle()': True,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:word.lower()': 'london',\n",
       "  'bias': 1.0,\n",
       "  'postag': 'TO',\n",
       "  'postag[:2]': 'TO',\n",
       "  'word.isdigit()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isupper()': False,\n",
       "  'word.lower()': 'to',\n",
       "  'word[-2:]': 'to',\n",
       "  'word[-3:]': 'to'},\n",
       " {'+1:postag': 'DT',\n",
       "  '+1:postag[:2]': 'DT',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:word.lower()': 'the',\n",
       "  '-1:postag': 'TO',\n",
       "  '-1:postag[:2]': 'TO',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:word.lower()': 'to',\n",
       "  'bias': 1.0,\n",
       "  'postag': 'VB',\n",
       "  'postag[:2]': 'VB',\n",
       "  'word.isdigit()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isupper()': False,\n",
       "  'word.lower()': 'protest',\n",
       "  'word[-2:]': 'st',\n",
       "  'word[-3:]': 'est'},\n",
       " {'+1:postag': 'NN',\n",
       "  '+1:postag[:2]': 'NN',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:word.lower()': 'war',\n",
       "  '-1:postag': 'VB',\n",
       "  '-1:postag[:2]': 'VB',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:word.lower()': 'protest',\n",
       "  'bias': 1.0,\n",
       "  'postag': 'DT',\n",
       "  'postag[:2]': 'DT',\n",
       "  'word.isdigit()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isupper()': False,\n",
       "  'word.lower()': 'the',\n",
       "  'word[-2:]': 'he',\n",
       "  'word[-3:]': 'the'},\n",
       " {'+1:postag': 'IN',\n",
       "  '+1:postag[:2]': 'IN',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:word.lower()': 'in',\n",
       "  '-1:postag': 'DT',\n",
       "  '-1:postag[:2]': 'DT',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:word.lower()': 'the',\n",
       "  'bias': 1.0,\n",
       "  'postag': 'NN',\n",
       "  'postag[:2]': 'NN',\n",
       "  'word.isdigit()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isupper()': False,\n",
       "  'word.lower()': 'war',\n",
       "  'word[-2:]': 'ar',\n",
       "  'word[-3:]': 'war'},\n",
       " {'+1:postag': 'NNP',\n",
       "  '+1:postag[:2]': 'NN',\n",
       "  '+1:word.istitle()': True,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:word.lower()': 'iraq',\n",
       "  '-1:postag': 'NN',\n",
       "  '-1:postag[:2]': 'NN',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:word.lower()': 'war',\n",
       "  'bias': 1.0,\n",
       "  'postag': 'IN',\n",
       "  'postag[:2]': 'IN',\n",
       "  'word.isdigit()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isupper()': False,\n",
       "  'word.lower()': 'in',\n",
       "  'word[-2:]': 'in',\n",
       "  'word[-3:]': 'in'},\n",
       " {'+1:postag': 'CC',\n",
       "  '+1:postag[:2]': 'CC',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:word.lower()': 'and',\n",
       "  '-1:postag': 'IN',\n",
       "  '-1:postag[:2]': 'IN',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:word.lower()': 'in',\n",
       "  'bias': 1.0,\n",
       "  'postag': 'NNP',\n",
       "  'postag[:2]': 'NN',\n",
       "  'word.isdigit()': False,\n",
       "  'word.istitle()': True,\n",
       "  'word.isupper()': False,\n",
       "  'word.lower()': 'iraq',\n",
       "  'word[-2:]': 'aq',\n",
       "  'word[-3:]': 'raq'},\n",
       " {'+1:postag': 'VB',\n",
       "  '+1:postag[:2]': 'VB',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:word.lower()': 'demand',\n",
       "  '-1:postag': 'NNP',\n",
       "  '-1:postag[:2]': 'NN',\n",
       "  '-1:word.istitle()': True,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:word.lower()': 'iraq',\n",
       "  'bias': 1.0,\n",
       "  'postag': 'CC',\n",
       "  'postag[:2]': 'CC',\n",
       "  'word.isdigit()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isupper()': False,\n",
       "  'word.lower()': 'and',\n",
       "  'word[-2:]': 'nd',\n",
       "  'word[-3:]': 'and'},\n",
       " {'+1:postag': 'DT',\n",
       "  '+1:postag[:2]': 'DT',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:word.lower()': 'the',\n",
       "  '-1:postag': 'CC',\n",
       "  '-1:postag[:2]': 'CC',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:word.lower()': 'and',\n",
       "  'bias': 1.0,\n",
       "  'postag': 'VB',\n",
       "  'postag[:2]': 'VB',\n",
       "  'word.isdigit()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isupper()': False,\n",
       "  'word.lower()': 'demand',\n",
       "  'word[-2:]': 'nd',\n",
       "  'word[-3:]': 'and'},\n",
       " {'+1:postag': 'NN',\n",
       "  '+1:postag[:2]': 'NN',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:word.lower()': 'withdrawal',\n",
       "  '-1:postag': 'VB',\n",
       "  '-1:postag[:2]': 'VB',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:word.lower()': 'demand',\n",
       "  'bias': 1.0,\n",
       "  'postag': 'DT',\n",
       "  'postag[:2]': 'DT',\n",
       "  'word.isdigit()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isupper()': False,\n",
       "  'word.lower()': 'the',\n",
       "  'word[-2:]': 'he',\n",
       "  'word[-3:]': 'the'},\n",
       " {'+1:postag': 'IN',\n",
       "  '+1:postag[:2]': 'IN',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:word.lower()': 'of',\n",
       "  '-1:postag': 'DT',\n",
       "  '-1:postag[:2]': 'DT',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:word.lower()': 'the',\n",
       "  'bias': 1.0,\n",
       "  'postag': 'NN',\n",
       "  'postag[:2]': 'NN',\n",
       "  'word.isdigit()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isupper()': False,\n",
       "  'word.lower()': 'withdrawal',\n",
       "  'word[-2:]': 'al',\n",
       "  'word[-3:]': 'wal'},\n",
       " {'+1:postag': 'JJ',\n",
       "  '+1:postag[:2]': 'JJ',\n",
       "  '+1:word.istitle()': True,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:word.lower()': 'british',\n",
       "  '-1:postag': 'NN',\n",
       "  '-1:postag[:2]': 'NN',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:word.lower()': 'withdrawal',\n",
       "  'bias': 1.0,\n",
       "  'postag': 'IN',\n",
       "  'postag[:2]': 'IN',\n",
       "  'word.isdigit()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isupper()': False,\n",
       "  'word.lower()': 'of',\n",
       "  'word[-2:]': 'of',\n",
       "  'word[-3:]': 'of'},\n",
       " {'+1:postag': 'NNS',\n",
       "  '+1:postag[:2]': 'NN',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:word.lower()': 'troops',\n",
       "  '-1:postag': 'IN',\n",
       "  '-1:postag[:2]': 'IN',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:word.lower()': 'of',\n",
       "  'bias': 1.0,\n",
       "  'postag': 'JJ',\n",
       "  'postag[:2]': 'JJ',\n",
       "  'word.isdigit()': False,\n",
       "  'word.istitle()': True,\n",
       "  'word.isupper()': False,\n",
       "  'word.lower()': 'british',\n",
       "  'word[-2:]': 'sh',\n",
       "  'word[-3:]': 'ish'},\n",
       " {'+1:postag': 'IN',\n",
       "  '+1:postag[:2]': 'IN',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:word.lower()': 'from',\n",
       "  '-1:postag': 'JJ',\n",
       "  '-1:postag[:2]': 'JJ',\n",
       "  '-1:word.istitle()': True,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:word.lower()': 'british',\n",
       "  'bias': 1.0,\n",
       "  'postag': 'NNS',\n",
       "  'postag[:2]': 'NN',\n",
       "  'word.isdigit()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isupper()': False,\n",
       "  'word.lower()': 'troops',\n",
       "  'word[-2:]': 'ps',\n",
       "  'word[-3:]': 'ops'},\n",
       " {'+1:postag': 'DT',\n",
       "  '+1:postag[:2]': 'DT',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:word.lower()': 'that',\n",
       "  '-1:postag': 'NNS',\n",
       "  '-1:postag[:2]': 'NN',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:word.lower()': 'troops',\n",
       "  'bias': 1.0,\n",
       "  'postag': 'IN',\n",
       "  'postag[:2]': 'IN',\n",
       "  'word.isdigit()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isupper()': False,\n",
       "  'word.lower()': 'from',\n",
       "  'word[-2:]': 'om',\n",
       "  'word[-3:]': 'rom'},\n",
       " {'+1:postag': 'NN',\n",
       "  '+1:postag[:2]': 'NN',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:word.lower()': 'country',\n",
       "  '-1:postag': 'IN',\n",
       "  '-1:postag[:2]': 'IN',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:word.lower()': 'from',\n",
       "  'bias': 1.0,\n",
       "  'postag': 'DT',\n",
       "  'postag[:2]': 'DT',\n",
       "  'word.isdigit()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isupper()': False,\n",
       "  'word.lower()': 'that',\n",
       "  'word[-2:]': 'at',\n",
       "  'word[-3:]': 'hat'},\n",
       " {'+1:postag': '.',\n",
       "  '+1:postag[:2]': '.',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:word.lower()': '.',\n",
       "  '-1:postag': 'DT',\n",
       "  '-1:postag[:2]': 'DT',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:word.lower()': 'that',\n",
       "  'bias': 1.0,\n",
       "  'postag': 'NN',\n",
       "  'postag[:2]': 'NN',\n",
       "  'word.isdigit()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isupper()': False,\n",
       "  'word.lower()': 'country',\n",
       "  'word[-2:]': 'ry',\n",
       "  'word[-3:]': 'try'},\n",
       " {'-1:postag': 'NN',\n",
       "  '-1:postag[:2]': 'NN',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:word.lower()': 'country',\n",
       "  'EOS': True,\n",
       "  'bias': 1.0,\n",
       "  'postag': '.',\n",
       "  'postag[:2]': '.',\n",
       "  'word.isdigit()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isupper()': False,\n",
       "  'word.lower()': '.',\n",
       "  'word[-2:]': '.',\n",
       "  'word[-3:]': '.'}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "print(len(X[0]))\n",
    "print(len(y[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-geo',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-geo',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-gpe',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the conditional random field (CRF) implementation provided by sklearn-crfsuite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn_crfsuite import CRF\n",
    "\n",
    "crf = CRF(algorithm='lbfgs',\n",
    "          c1=0.1,\n",
    "          c2=0.1,\n",
    "          max_iterations=100,\n",
    "          all_possible_transitions=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we performe a 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_predict\n",
    "from sklearn_crfsuite.metrics import flat_classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = cross_val_predict(estimator=crf, X=X, y=y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-art       0.37      0.11      0.17       402\n",
      "      B-eve       0.52      0.35      0.42       308\n",
      "      B-geo       0.85      0.90      0.88     37644\n",
      "      B-gpe       0.97      0.94      0.95     15870\n",
      "      B-nat       0.66      0.37      0.47       201\n",
      "      B-org       0.78      0.72      0.75     20143\n",
      "      B-per       0.84      0.81      0.82     16990\n",
      "      B-tim       0.93      0.88      0.90     20333\n",
      "      I-art       0.11      0.03      0.04       297\n",
      "      I-eve       0.34      0.21      0.26       253\n",
      "      I-geo       0.82      0.79      0.80      7414\n",
      "      I-gpe       0.92      0.55      0.69       198\n",
      "      I-nat       0.61      0.27      0.38        51\n",
      "      I-org       0.81      0.79      0.80     16784\n",
      "      I-per       0.84      0.89      0.87     17251\n",
      "      I-tim       0.83      0.76      0.80      6528\n",
      "          O       0.99      0.99      0.99    887908\n",
      "\n",
      "avg / total       0.97      0.97      0.97   1048575\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = flat_classification_report(y_pred=pred, y_true=y)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
