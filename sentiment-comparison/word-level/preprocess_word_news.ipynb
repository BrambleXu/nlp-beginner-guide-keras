{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 read data from text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#======================== import module order as three level========================\n",
    "import os\n",
    "from os.path import join, exists, split\n",
    "import numpy as np\n",
    "import data_helpers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import model_from_json\n",
    "from keras.callbacks import TensorBoard\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    }
   ],
   "source": [
    "#TODO: After complete all training, use argparse to store the params.\n",
    "positive_data_file = \"../data/rt-polaritydata/rt-polarity.pos\"\n",
    "negtive_data_file = \"../data/rt-polaritydata/rt-polarity.neg\"\n",
    "\n",
    "# Load data\n",
    "print(\"Loading data...\")\n",
    "x_text, y = data_helpers.load_data_and_labels(positive_data_file, negtive_data_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = [len(sent) for sent in x_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max length\n",
    "max(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# min length\n",
    "min(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.38585631213656"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average\n",
    "sum(length) / len(length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the length is not too loog, so we set the sequence length as 56. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 string to index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=======================Convert string to index================\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Tokenizer\n",
    "tk = Tokenizer(num_words=None, oov_token='UNK')\n",
    "tk.fit_on_texts(x_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18765"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk.word_index['UNK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string to index \n",
    "sequences = tk.texts_to_sequences(x_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 565, 7, 2633, 6, 22, 1, 3369, 887, 8, 100, 5598, 4, 11, 65, 8, 240, 6, 73, 3, 3913, 57, 2948, 34, 1489, 2393, 2, 2394, 10111, 1708, 7197, 42, 937, 10112], [1, 3370, 2181, 7198, 5, 1, 3914, 5, 1, 2949, 4631, 7, 39, 1075, 11, 3, 7199, 5, 823, 888, 4632, 2634, 685, 246, 66, 1076, 889, 8, 4633, 686, 5, 1241, 1709, 1709, 5599, 8, 480, 1490]]\n"
     ]
    }
   ],
   "source": [
    "print(train_sequences[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding\n",
    "sequences_pad = pad_sequences(sequences, maxlen=56, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    1   565     7  2633     6    22     1  3369   887     8   100  5598\n",
      "      4    11    65     8   240     6    73     3  3913    57  2948    34\n",
      "   1489  2393     2  2394 10111  1708  7197    42   937 10112     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0]\n",
      " [    1  3370  2181  7198     5     1  3914     5     1  2949  4631     7\n",
      "     39  1075    11     3  7199     5   823   888  4632  2634   685   246\n",
      "     66  1076   889     8  4633   686     5  1241  1709  1709  5599     8\n",
      "    480  1490     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0]]\n"
     ]
    }
   ],
   "source": [
    "print(sequences_pad[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10662, 56)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18765"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tk.word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 word embedding \n",
    "\n",
    "The vocab size is 18765, so we will use Glove to build a 18766x50 word embedding weights. First row is represent padding which contain all 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the 0.418 0.24968 -0.41242 0.1217 0.34527 -0.044457 -0.49688 -0.17862 -0.00066023 -0.6566 0.27843 -0.14767 -0.55677 0.14658 -0.0095095 0.011658 0.10204 -0.12792 -0.8443 -0.12181 -0.016801 -0.33279 -0.1552 -0.23131 -0.19181 -1.8823 -0.76746 0.099051 -0.42125 -0.19526 4.0071 -0.18594 -0.52287 -0.31681 0.00059213 0.0074449 0.17778 -0.15897 0.012041 -0.054223 -0.29871 -0.15749 -0.34758 -0.045637 -0.44251 0.18785 0.0027849 -0.18411 -0.11514 -0.78581\n",
      "\n",
      ", 0.013441 0.23682 -0.16899 0.40951 0.63812 0.47709 -0.42852 -0.55641 -0.364 -0.23938 0.13001 -0.063734 -0.39575 -0.48162 0.23291 0.090201 -0.13324 0.078639 -0.41634 -0.15428 0.10068 0.48891 0.31226 -0.1252 -0.037512 -1.5179 0.12612 -0.02442 -0.042961 -0.28351 3.5416 -0.11956 -0.014533 -0.1499 0.21864 -0.33412 -0.13872 0.31806 0.70358 0.44858 -0.080262 0.63003 0.32111 -0.46765 0.22786 0.36034 -0.37818 -0.56657 0.044691 0.30392\n",
      "\n"
     ]
    }
   ],
   "source": [
    "glove_path = 'glove.6B'\n",
    "with open(os.path.join(glove_path, 'glove.6B.50d.txt')) as f:\n",
    "    i = 0\n",
    "    for line in f.readlines():\n",
    "        print(line)\n",
    "#         print(line.split())\n",
    "        i += 1\n",
    "        if i > 1:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read glove to embedding\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join(glove_path, 'glove.6B.50d.txt'))\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.1800e-01,  2.4968e-01, -4.1242e-01,  1.2170e-01,  3.4527e-01,\n",
       "       -4.4457e-02, -4.9688e-01, -1.7862e-01, -6.6023e-04, -6.5660e-01,\n",
       "        2.7843e-01, -1.4767e-01, -5.5677e-01,  1.4658e-01, -9.5095e-03,\n",
       "        1.1658e-02,  1.0204e-01, -1.2792e-01, -8.4430e-01, -1.2181e-01,\n",
       "       -1.6801e-02, -3.3279e-01, -1.5520e-01, -2.3131e-01, -1.9181e-01,\n",
       "       -1.8823e+00, -7.6746e-01,  9.9051e-02, -4.2125e-01, -1.9526e-01,\n",
       "        4.0071e+00, -1.8594e-01, -5.2287e-01, -3.1681e-01,  5.9213e-04,\n",
       "        7.4449e-03,  1.7778e-01, -1.5897e-01,  1.2041e-02, -5.4223e-02,\n",
       "       -2.9871e-01, -1.5749e-01, -3.4758e-01, -4.5637e-02, -4.4251e-01,\n",
       "        1.8785e-01,  2.7849e-03, -1.8411e-01, -1.1514e-01, -7.8581e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_index['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5.2395954"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_index['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.16135411,  0.03557489, -0.09522059, -0.1242005 ,  0.06621048,\n",
       "       -0.09528465, -0.12728056,  0.07979754,  0.09633083,  0.20050312,\n",
       "       -0.05113975, -0.00972726, -0.02855471, -0.01472568, -0.03357385,\n",
       "        0.1873512 ,  0.03185613, -0.04298057, -0.17279828, -0.20144806,\n",
       "       -0.03849123,  0.08185671,  0.16343176,  0.09456343, -0.04212118,\n",
       "       -0.03696294, -0.11233464,  0.03048478,  0.02966199, -0.06009029,\n",
       "       -0.07345058, -0.03272793, -0.04158637, -0.06199308, -0.15955818,\n",
       "        0.16222283, -0.16236277, -0.09712829,  0.01742469,  0.00733383,\n",
       "       -0.00704928,  0.0138043 , -0.06280551, -0.13909955, -0.06535425,\n",
       "        0.05937353,  0.23325249,  0.06374299,  0.09044405, -0.01901892])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu, sigma = 0, 0.1 # mean and standard deviation\n",
    "s = np.random.normal(mu, sigma, 50)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add random vector to 'UNK'\n",
    "embeddings_index['UNK'] = np.random.normal(mu, sigma, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 50\n",
    "\n",
    "# use embeddings_index to build our embedding_matrix\n",
    "embedding_matrix = np.zeros((len(tk.word_index)+1, embedding_dim)) # fist row represent 0, pad\n",
    "for word, i in tk.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word) # if not find in the dict, return None\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    else:\n",
    "        embedding_vector = embeddings_index.get('UNK')\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18766, 50)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
