{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About the data\n",
    "\n",
    "This is the sentiment140 dataset. \n",
    "It contains 1,600,000 tweets extracted using the twitter api . The tweets have been annotated (0 = negative, 2 = neutral, 4 = positive) and they can be used to detect sentiment . \n",
    "It contains the following 6 fields:\n",
    "\n",
    " 1. **target**: the polarity of the tweet (*0* = negative, *2* = neutral, *4* = positive)\n",
    " 2. **ids**: The id of the tweet ( *2087*)\n",
    " 3. **date**: the date of the tweet (*Sat May 16 23:58:44 UTC 2009*)\n",
    " 4. **flag**: The query (*lyx*). If there is no query, then this value is NO_QUERY.\n",
    " 5. **user**: the user that tweeted (*robotickilldozr*)\n",
    " 6.  **text**: the text of the tweet (*Lyx is cool*)\n",
    "\n",
    "\n",
    "The official link regarding the dataset with resources about how it was generated is [here][1] \n",
    "The official paper detailing the approach is [here][2] \n",
    "\n",
    "According to the creators of the dataset:\n",
    "\n",
    "\"Our approach was unique because our training data was automatically created, as opposed to having humans manual annotate tweets. In our approach, we assume that any tweet with positive emoticons, like :), were positive, and tweets with negative emoticons, like :(, were negative. We used the Twitter Search API to collect these tweets by using keyword search\"\n",
    "\n",
    "citation: Go, A., Bhayani, R. and Huang, L., 2009. Twitter sentiment classification using distant supervision. *CS224N Project Report, Stanford, 1(2009), p.12*.\n",
    "\n",
    "\n",
    "  [1]: http://%20http://help.sentiment140.com/for-students/\n",
    "  [2]: http://bhttp://cs.stanford.edu/people/alecmgo/papers/TwitterDistantSupervision09.pdf\n",
    "  \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First look at the data\n",
    "\n",
    "This file is based on https://github.com/tthustla/twitter_sentiment_analysis_part1/blob/master/Capstone_part2.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['sentiment','id','date','query_string','user','text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mtraining.1600000.processed.noemoticon.csv\u001b[m\u001b[m*\r\n"
     ]
    }
   ],
   "source": [
    "ls ../data/twitter/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read_csv takes an encoding option to deal with files in different formats. I mostly use read_csv('file', encoding = \"ISO-8859-1\"), or alternatively encoding = \"utf-8\" for reading, and generally utf-8 for to_csv.\n",
    "\n",
    "You can also use the alias 'latin1' instead of 'ISO-8859-1'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  encoding='latin1'\n",
    "df = pd.read_csv(\"../data/twitter/training.1600000.processed.noemoticon.csv\", header=None, names=cols, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>query_string</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment          id                          date query_string  \\\n",
       "0          0  1467810369  Mon Apr 06 22:19:45 PDT 2009     NO_QUERY   \n",
       "1          0  1467810672  Mon Apr 06 22:19:49 PDT 2009     NO_QUERY   \n",
       "2          0  1467810917  Mon Apr 06 22:19:53 PDT 2009     NO_QUERY   \n",
       "3          0  1467811184  Mon Apr 06 22:19:57 PDT 2009     NO_QUERY   \n",
       "4          0  1467811193  Mon Apr 06 22:19:57 PDT 2009     NO_QUERY   \n",
       "\n",
       "              user                                               text  \n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1600000 entries, 0 to 1599999\n",
      "Data columns (total 6 columns):\n",
      "sentiment       1600000 non-null int64\n",
      "id              1600000 non-null int64\n",
      "date            1600000 non-null object\n",
      "query_string    1600000 non-null object\n",
      "user            1600000 non-null object\n",
      "text            1600000 non-null object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 73.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    800000\n",
       "0    800000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NO_QUERY    1600000\n",
       "Name: query_string, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.query_string.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['id','date','query_string','user'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text\n",
       "0          0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1          0  is upset that he can't update his Facebook by ...\n",
       "2          0  @Kenichan I dived many times for the ball. Man...\n",
       "3          0    my whole body feels itchy and like its on fire \n",
       "4          0  @nationwideclass no, it's not behaving at all...."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>Need a hug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>@LOLTrish hey  long time no see! Yes.. Rains a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>@Tatiana_K nope they didn't have it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>@twittera que me muera ?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text\n",
       "0          0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1          0  is upset that he can't update his Facebook by ...\n",
       "2          0  @Kenichan I dived many times for the ball. Man...\n",
       "3          0    my whole body feels itchy and like its on fire \n",
       "4          0  @nationwideclass no, it's not behaving at all....\n",
       "5          0                      @Kwesidei not the whole crew \n",
       "6          0                                        Need a hug \n",
       "7          0  @LOLTrish hey  long time no see! Yes.. Rains a...\n",
       "8          0               @Tatiana_K nope they didn't have it \n",
       "9          0                          @twittera que me muera ? "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.sentiment == 0].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>800000</th>\n",
       "      <td>4</td>\n",
       "      <td>I LOVE @Health4UandPets u guys r the best!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800001</th>\n",
       "      <td>4</td>\n",
       "      <td>im meeting up with one of my besties tonight! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800002</th>\n",
       "      <td>4</td>\n",
       "      <td>@DaRealSunisaKim Thanks for the Twitter add, S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800003</th>\n",
       "      <td>4</td>\n",
       "      <td>Being sick can be really cheap when it hurts t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800004</th>\n",
       "      <td>4</td>\n",
       "      <td>@LovesBrooklyn2 he has that effect on everyone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800005</th>\n",
       "      <td>4</td>\n",
       "      <td>@ProductOfFear You can tell him that I just bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800006</th>\n",
       "      <td>4</td>\n",
       "      <td>@r_keith_hill Thans for your response. Ihad al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800007</th>\n",
       "      <td>4</td>\n",
       "      <td>@KeepinUpWKris I am so jealous, hope you had a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800008</th>\n",
       "      <td>4</td>\n",
       "      <td>@tommcfly ah, congrats mr fletcher for finally...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800009</th>\n",
       "      <td>4</td>\n",
       "      <td>@e4VoIP I RESPONDED  Stupid cat is helping me ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentiment                                               text\n",
       "800000          4       I LOVE @Health4UandPets u guys r the best!! \n",
       "800001          4  im meeting up with one of my besties tonight! ...\n",
       "800002          4  @DaRealSunisaKim Thanks for the Twitter add, S...\n",
       "800003          4  Being sick can be really cheap when it hurts t...\n",
       "800004          4    @LovesBrooklyn2 he has that effect on everyone \n",
       "800005          4  @ProductOfFear You can tell him that I just bu...\n",
       "800006          4  @r_keith_hill Thans for your response. Ihad al...\n",
       "800007          4  @KeepinUpWKris I am so jealous, hope you had a...\n",
       "800008          4  @tommcfly ah, congrats mr fletcher for finally...\n",
       "800009          4  @e4VoIP I RESPONDED  Stupid cat is helping me ..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.sentiment == 4].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at some entries for each class, it seems like that all the negative class is from 0~799999th index, and the positive class entries start from 800000 to the end of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([     0,      1,      2,      3,      4,      5,      6,      7,\n",
       "                 8,      9,\n",
       "            ...\n",
       "            799990, 799991, 799992, 799993, 799994, 799995, 799996, 799997,\n",
       "            799998, 799999],\n",
       "           dtype='int64', length=800000)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.sentiment == 0].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([ 800000,  800001,  800002,  800003,  800004,  800005,  800006,\n",
       "             800007,  800008,  800009,\n",
       "            ...\n",
       "            1599990, 1599991, 1599992, 1599993, 1599994, 1599995, 1599996,\n",
       "            1599997, 1599998, 1599999],\n",
       "           dtype='int64', length=800000)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.sentiment == 4].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the class value of 4(positive) to 1\n",
    "df['sentiment'] = df['sentiment'].map({0: 0, 4: 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    800000\n",
       "0    800000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>query_string</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [sentiment, id, date, query_string, user, text]\n",
       "Index: []"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pre_clean_len'] = [len(t) for t in df.text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>pre_clean_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text  pre_clean_len\n",
       "0          0  @switchfoot http://twitpic.com/2y1zl - Awww, t...            115\n",
       "1          0  is upset that he can't update his Facebook by ...            111\n",
       "2          0  @Kenichan I dived many times for the ball. Man...             89\n",
       "3          0    my whole body feels itchy and like its on fire              47\n",
       "4          0  @nationwideclass no, it's not behaving at all....            111"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.600000e+06\n",
       "mean     7.409011e+01\n",
       "std      3.644114e+01\n",
       "min      6.000000e+00\n",
       "25%      4.400000e+01\n",
       "50%      6.900000e+01\n",
       "75%      1.040000e+02\n",
       "max      3.740000e+02\n",
       "Name: pre_clean_len, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pre_clean_len'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Dictionary - first draft\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_shape': (1600000, 3),\n",
      " 'pre_clean_len': {'description': 'Length of the tweet before cleaning',\n",
      "                   'type': dtype('int64')},\n",
      " 'sentiment': {'description': 'sentiment class - 0:negative, 1:positive',\n",
      "               'type': dtype('int64')},\n",
      " 'text': {'description': 'tweet text', 'type': dtype('O')}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "data_dict = {\n",
    "    'sentiment':{\n",
    "        'type':df.sentiment.dtype,\n",
    "        'description':'sentiment class - 0:negative, 1:positive'\n",
    "    },\n",
    "    'text':{\n",
    "        'type':df.text.dtype,\n",
    "        'description':'tweet text'\n",
    "    },\n",
    "    'pre_clean_len':{\n",
    "        'type':df.pre_clean_len.dtype,\n",
    "        'description':'Length of the tweet before cleaning'\n",
    "    },\n",
    "    'dataset_shape':df.shape\n",
    "}\n",
    "\n",
    "pprint(data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will also plot pre_clean_len with box plot, so that I can see the overall distribution of length of strings in each entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x112c74828>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 299,
       "width": 350
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "plt.boxplot(df.pre_clean_len)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks a bit strange, since the twitter's character limit is 140. But from the above box plot, some of the tweets are way more than 140 chracters long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>pre_clean_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>0</td>\n",
       "      <td>Awwh babs... you look so sad underneith that s...</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>0</td>\n",
       "      <td>Tuesdayll start with reflection n then a...</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>0</td>\n",
       "      <td>Whinging. My client&amp;amp;boss don't understand ...</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>0</td>\n",
       "      <td>@TheLeagueSF Not Fun &amp;amp; Furious? The new ma...</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>0</td>\n",
       "      <td>#3 woke up and was having an accident - &amp;quot;...</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>0</td>\n",
       "      <td>My bathtub drain is fired: it haz 1 job 2 do, ...</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>0</td>\n",
       "      <td>pears &amp;amp; Brie, bottle of Cabernet, and &amp;quo...</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>0</td>\n",
       "      <td>Have an invite for &amp;quot;Healthy Dining&amp;quot; ...</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>0</td>\n",
       "      <td>Damnit I was really digging this season of Rea...</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064</th>\n",
       "      <td>0</td>\n",
       "      <td>Why do I keep looking...I know that what I rea...</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiment                                               text  \\\n",
       "213           0  Awwh babs... you look so sad underneith that s...   \n",
       "226           0  Tuesdayll start with reflection n then a...   \n",
       "279           0  Whinging. My client&amp;boss don't understand ...   \n",
       "343           0  @TheLeagueSF Not Fun &amp; Furious? The new ma...   \n",
       "400           0  #3 woke up and was having an accident - &quot;...   \n",
       "464           0  My bathtub drain is fired: it haz 1 job 2 do, ...   \n",
       "492           0  pears &amp; Brie, bottle of Cabernet, and &quo...   \n",
       "747           0  Have an invite for &quot;Healthy Dining&quot; ...   \n",
       "957           0  Damnit I was really digging this season of Rea...   \n",
       "1064          0  Why do I keep looking...I know that what I rea...   \n",
       "\n",
       "      pre_clean_len  \n",
       "213             142  \n",
       "226             141  \n",
       "279             145  \n",
       "343             145  \n",
       "400             144  \n",
       "464             146  \n",
       "492             150  \n",
       "747             141  \n",
       "957             141  \n",
       "1064            141  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.pre_clean_len > 140].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation 1: HTML decoding\n",
    "\n",
    "It looks like HTML encoding has not been converted to text, and ended up in text field as '&amp','&quot',etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Whinging. My client&amp;boss don't understand English well. Rewrote some text unreadable. It's written by v. good writer&amp;reviewed correctly. \""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text[279]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whinging. My client&boss don't understand English well. Rewrote some text unreadable. It's written by v. good writer&reviewed correctly. \n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "example1 = BeautifulSoup(df.text[279], 'lxml')\n",
    "print(example1.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation 2: @mention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@TheLeagueSF Not Fun &amp; Furious? The new mantra for the Bay 2 Breakers? It was getting 2 rambunctious;the city overreacted &amp; clamped down '"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text[343]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Not Fun &amp; Furious? The new mantra for the Bay 2 Breakers? It was getting 2 rambunctious;the city overreacted &amp; clamped down '"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "re.sub(r'@[A-Za-z0-9]+','',df.text[343])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation 3: URL links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"@switchfoot  - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub('https?://[A-Za-z0-9./]+','', df.text[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation 4: UTF-8 BOM (Byte Order Mark)\n",
    "\n",
    "With the Latin 1 (ISO 8859-1) character encoding, the signature displays as characters ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tuesdayll start with reflection n then a lecture in Stress reducing techniques. That sure might become very useful for us accompaniers '"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text[226]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = df.text[226]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tuesday?ll start with reflection ?n then a lecture in Stress reducing techniques. That sure might become very useful for us accompaniers '"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing.replace(u'', '?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation 5: hashtag / numbers\n",
    "\n",
    "Sometimes the text used with a hashtag can provide useful information about the tweet. It might be a bit risky to get rid of all the text together with the hashtag.\n",
    "So I decided to leave the text intact and just remove the '#'. I will do this in the process of cleaning all the non-letter characters including numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"@machineplay I'm so sorry you're having to go through this. Again.  #therapyfail\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text[175]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' machineplay I m so sorry you re having to go through this  Again    therapyfail'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(\"[^a-zA-Z]\", \" \", df.text[175])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining data cleaning function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "tok = WordPunctTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat1 = r'@[A-Za-z0-9]+'\n",
    "pat2 = r'https?://[A-Za-z0-9./]+'\n",
    "combined_pat = r'|'.join((pat1, pat2))\n",
    "\n",
    "def tweet_cleaner(text):\n",
    "    soup = BeautifulSoup(text, 'lxml')\n",
    "    souped = soup.get_text()\n",
    "    stripped = re.sub(combined_pat, '', souped)\n",
    "    try:\n",
    "        clean = stripped.replace(u'', '?')\n",
    "    except:\n",
    "        clean = stripped\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", clean)\n",
    "    lower_case = letters_only.lower()\n",
    "    # During the letters_only process two lines above, it has created unnecessay white spaces,\n",
    "    # I will tokenize and join together to remove unneccessary white spaces\n",
    "    words = tok.tokenize(lower_case)\n",
    "    return (\" \".join(words)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1     is upset that he can't update his Facebook by ...\n",
       "2     @Kenichan I dived many times for the ball. Man...\n",
       "3       my whole body feels itchy and like its on fire \n",
       "4     @nationwideclass no, it's not behaving at all....\n",
       "5                         @Kwesidei not the whole crew \n",
       "6                                           Need a hug \n",
       "7     @LOLTrish hey  long time no see! Yes.. Rains a...\n",
       "8                  @Tatiana_K nope they didn't have it \n",
       "9                             @twittera que me muera ? \n",
       "10          spring break in plain city... it's snowing \n",
       "11                           I just re-pierced my ears \n",
       "12    @caregiving I couldn't bear to watch it.  And ...\n",
       "13    @octolinz16 It it counts, idk why I did either...\n",
       "14    @smarrison i would've been the first, but i di...\n",
       "15    @iamjazzyfizzle I wish I got to watch it with ...\n",
       "16    Hollis' death scene will hurt me severely to w...\n",
       "17                                 about to file taxes \n",
       "18    @LettyA ahh ive always wanted to see rent  lov...\n",
       "19    @FakerPattyPattz Oh dear. Were you drinking ou...\n",
       "20    @alydesigns i was out most of the day so didn'...\n",
       "21    one of my friend called me, and asked to meet ...\n",
       "22     @angry_barista I baked you a cake but I ated it \n",
       "23               this week is not going as i had hoped \n",
       "24                           blagh class at 8 tomorrow \n",
       "25       I hate when I have to call and wake people up \n",
       "26    Just going to cry myself to sleep after watchi...\n",
       "27                               im sad now  Miss.Lilly\n",
       "28    ooooh.... LOL  that leslie.... and ok I won't ...\n",
       "29    Meh... Almost Lover is the exception... this t...\n",
       "                            ...                        \n",
       "70    @jdarter Oh! Haha... dude I dont really look a...\n",
       "71    @ninjen I'm sure you're right...    I need to ...\n",
       "72    i really hate how people diss my bands!  Trace...\n",
       "73    Gym attire today was: Puma singlet, Adidas sho...\n",
       "74    Why won't you show my location?!   http://twit...\n",
       "75              No picnic  my phone smells like citrus.\n",
       "76    @ashleyac My donkey is sensitive about such co...\n",
       "77                             No new csi tonight.  FML\n",
       "78                i think my arms are sore from tennis \n",
       "79    wonders why someone that u like so much can ma...\n",
       "80    sleep soon... i just hate saying bye and see y...\n",
       "81    @statravelAU just got ur newsletter, those far...\n",
       "82                                     missin' the boo \n",
       "83                          @markhardy1974 Me too  #itm\n",
       "84    Damn... I don't have any chalk! MY CHALKBOARD ...\n",
       "85    had a blast at the Getty Villa, but hates that...\n",
       "86      @msdrama hey missed ya at the meeting  sup mama\n",
       "87    My tummy hurts.  I wonder if the hypnosis has ...\n",
       "88                     why is it always the fat ones?! \n",
       "89    @januarycrimson Sorry, babe!!  My fam annoys m...\n",
       "90    @Hollywoodheat I should have paid more attenti...\n",
       "91          wednesday my b-day! don't know what 2 do!! \n",
       "92                            Poor cameron (the hills) \n",
       "93    pray for me please, the ex is threatening to s...\n",
       "94    @makeherfamous hmm  , do u really enjoy being ...\n",
       "95    Strider is a sick little puppy  http://apps.fa...\n",
       "96    so rylee,grace...wana go steve's party or not?...\n",
       "97    hey, I actually won one of my bracket pools! T...\n",
       "98    @stark YOU don't follow me, either  and i work...\n",
       "99    A bad nite for the favorite teams: Astros and ...\n",
       "Name: text, Length: 100, dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing = df.text[:100]\n",
    "testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result = []\n",
    "for t in testing:\n",
    "    test_result.append(tweet_cleaner(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['awww that s a bummer you shoulda got david carr of third day to do it d',\n",
       " 'is upset that he can t update his facebook by texting it and might cry as a result school today also blah',\n",
       " 'i dived many times for the ball managed to save the rest go out of bounds',\n",
       " 'my whole body feels itchy and like its on fire',\n",
       " 'no it s not behaving at all i m mad why am i here because i can t see you all over there',\n",
       " 'not the whole crew',\n",
       " 'need a hug',\n",
       " 'hey long time no see yes rains a bit only a bit lol i m fine thanks how s you',\n",
       " 'k nope they didn t have it',\n",
       " 'que me muera',\n",
       " 'spring break in plain city it s snowing',\n",
       " 'i just re pierced my ears',\n",
       " 'i couldn t bear to watch it and i thought the ua loss was embarrassing',\n",
       " 'it it counts idk why i did either you never talk to me anymore',\n",
       " 'i would ve been the first but i didn t have a gun not really though zac snyder s just a doucheclown',\n",
       " 'i wish i got to watch it with you i miss you and how was the premiere',\n",
       " 'hollis death scene will hurt me severely to watch on film wry is directors cut not out now',\n",
       " 'about to file taxes',\n",
       " 'ahh ive always wanted to see rent love the soundtrack',\n",
       " 'oh dear were you drinking out of the forgotten table drinks',\n",
       " 'i was out most of the day so didn t get much done',\n",
       " 'one of my friend called me and asked to meet with her at mid valley today but i ve no time sigh',\n",
       " 'barista i baked you a cake but i ated it',\n",
       " 'this week is not going as i had hoped',\n",
       " 'blagh class at tomorrow',\n",
       " 'i hate when i have to call and wake people up',\n",
       " 'just going to cry myself to sleep after watching marley and me',\n",
       " 'im sad now miss lilly',\n",
       " 'ooooh lol that leslie and ok i won t do it again so leslie won t get mad again',\n",
       " 'meh almost lover is the exception this track gets me depressed every time',\n",
       " 'some hacked my account on aim now i have to make a new one',\n",
       " 'i want to go to promote gear and groove but unfornately no ride there i may b going to the one in anaheim in may though',\n",
       " 'thought sleeping in was an option tomorrow but realizing that it now is not evaluations in the morning and work in the afternoon',\n",
       " 'awe i love you too am here i miss you',\n",
       " 'i cry my asian eyes to sleep at night',\n",
       " 'ok i m sick and spent an hour sitting in the shower cause i was too sick to stand and held back the puke like a champ bed now',\n",
       " 'ill tell ya the story later not a good day and ill be workin for like three more hours',\n",
       " 'sorry bed time came here gmt',\n",
       " 'i don t either its depressing i don t think i even want to know about the kids in suitcases',\n",
       " 'bed class work gym or then class another day that s gonna fly by i miss my girlfriend',\n",
       " 'really don t feel like getting up today but got to study to for tomorrows practical exam',\n",
       " 'he s the reason for the teardrops on my guitar the only one who has enough of me to break my heart',\n",
       " 'sad sad sad i don t know why but i hate this feeling i wanna sleep and i still can t',\n",
       " 'awww i soo wish i was there to see you finally comfortable im sad that i missed it',\n",
       " 'falling asleep just heard about that tracy girl s body being found how sad my heart breaks for that family',\n",
       " 'yay i m happy for you with your job but that also means less time for me and you',\n",
       " 'just checked my user timeline on my blackberry it looks like the twanking is still happening are ppl still having probs w bgs and uids',\n",
       " 'oh man was ironing s fave top to wear to a meeting burnt it',\n",
       " 'is strangely sad about lilo and samro breaking up',\n",
       " 'oh i m so sorry i didn t think about that before retweeting',\n",
       " 'broadband plan a massive broken promise via www diigo com tautao still waiting for broadband we are',\n",
       " 'wow tons of replies from you may have to unfollow so i can see my friends tweets you re scrolling the feed a lot',\n",
       " 'our duck and chicken are taking wayyy too long to hatch',\n",
       " 'put vacation photos online a few yrs ago pc crashed and now i forget the name of the site',\n",
       " 'i need a hug',\n",
       " 'not sure what they are only that they are pos as much as i want to i dont think can trade away company assets sorry andy',\n",
       " 'i hate when that happens',\n",
       " 'i have a sad feeling that dallas is not going to show up i gotta say though you d think more shows would use music from the game mmm',\n",
       " 'ugh degrees tomorrow',\n",
       " 'where did u move to i thought u were already in sd hmmm random u found me glad to hear yer doing well',\n",
       " 'i miss my ps it s out of commission wutcha playing have you copped blood on the sand',\n",
       " 'just leaving the parking lot of work',\n",
       " 'the life is cool but not for me',\n",
       " 'sadly though i ve never gotten to experience the post coitus cigarette before and now i never will',\n",
       " 'i had such a nice day too bad the rain comes in tomorrow at am',\n",
       " 'too bad i won t be around i lost my job and can t even pay my phone bill lmao aw shucks',\n",
       " 'damm back to school tomorrow',\n",
       " 'mo jobs no money how in the hell is min wage here f n clams an hour',\n",
       " 'not forever see you soon',\n",
       " 'algonquin agreed i saw the failwhale allllll day today',\n",
       " 'oh haha dude i dont really look at em unless someone says hey i added you sorry i m so terrible at that i need a pop up',\n",
       " 'i m sure you re right i need to start working out with you and the nikster or jared at least',\n",
       " 'i really hate how people diss my bands trace is clearly not ugly',\n",
       " 'gym attire today was puma singlet adidas shorts and black business socks and leather shoes lucky did not run into any cute girls',\n",
       " 'why won t you show my location',\n",
       " 'no picnic my phone smells like citrus',\n",
       " 'my donkey is sensitive about such comments nevertheless he d and me d be glad to see your mug asap charger is still awol',\n",
       " 'no new csi tonight fml',\n",
       " 'i think my arms are sore from tennis',\n",
       " 'wonders why someone that u like so much can make you so unhappy in a split seccond depressed',\n",
       " 'sleep soon i just hate saying bye and see you tomorrow for the night',\n",
       " 'just got ur newsletter those fares really are unbelievable shame i already booked and paid for mine',\n",
       " 'missin the boo',\n",
       " 'me too itm',\n",
       " 'damn i don t have any chalk my chalkboard is useless',\n",
       " 'had a blast at the getty villa but hates that she s had a sore throat all day it s just getting worse too',\n",
       " 'hey missed ya at the meeting sup mama',\n",
       " 'my tummy hurts i wonder if the hypnosis has anything to do with it if so it s working i get it stop smoking',\n",
       " 'why is it always the fat ones',\n",
       " 'sorry babe my fam annoys me too thankfully they re asleep right now muahaha evil laugh',\n",
       " 'i should have paid more attention when we covered photoshop in my webpage design class in undergrad',\n",
       " 'wednesday my b day don t know what do',\n",
       " 'poor cameron the hills',\n",
       " 'pray for me please the ex is threatening to start sh at my our babies st birthday party what a jerk and i still have a headache',\n",
       " 'hmm do u really enjoy being with him if the problems are too constants u should think things more find someone ulike',\n",
       " 'strider is a sick little puppy',\n",
       " 'so rylee grace wana go steve s party or not sadly since its easter i wnt b able do much but ohh well',\n",
       " 'hey i actually won one of my bracket pools too bad it wasn t the one for money',\n",
       " 'you don t follow me either and i work for you',\n",
       " 'a bad nite for the favorite teams astros and spartans lose the nite out with t w was good']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = [0,400000,800000,1200000,1600000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and parsing the tweets...\n",
      "\n",
      "Tweets 10000 of 400000 has been processed\n",
      "Tweets 20000 of 400000 has been processed\n",
      "Tweets 30000 of 400000 has been processed\n",
      "Tweets 40000 of 400000 has been processed\n",
      "Tweets 50000 of 400000 has been processed\n",
      "Tweets 60000 of 400000 has been processed\n",
      "Tweets 70000 of 400000 has been processed\n",
      "Tweets 80000 of 400000 has been processed\n",
      "Tweets 90000 of 400000 has been processed\n",
      "Tweets 100000 of 400000 has been processed\n",
      "Tweets 110000 of 400000 has been processed\n",
      "Tweets 120000 of 400000 has been processed\n",
      "Tweets 130000 of 400000 has been processed\n",
      "Tweets 140000 of 400000 has been processed\n",
      "Tweets 150000 of 400000 has been processed\n",
      "Tweets 160000 of 400000 has been processed\n",
      "Tweets 170000 of 400000 has been processed\n",
      "Tweets 180000 of 400000 has been processed\n",
      "Tweets 190000 of 400000 has been processed\n",
      "Tweets 200000 of 400000 has been processed\n",
      "Tweets 210000 of 400000 has been processed\n",
      "Tweets 220000 of 400000 has been processed\n",
      "Tweets 230000 of 400000 has been processed\n",
      "Tweets 240000 of 400000 has been processed\n",
      "Tweets 250000 of 400000 has been processed\n",
      "Tweets 260000 of 400000 has been processed\n",
      "Tweets 270000 of 400000 has been processed\n",
      "Tweets 280000 of 400000 has been processed\n",
      "Tweets 290000 of 400000 has been processed\n",
      "Tweets 300000 of 400000 has been processed\n",
      "Tweets 310000 of 400000 has been processed\n",
      "Tweets 320000 of 400000 has been processed\n",
      "Tweets 330000 of 400000 has been processed\n",
      "Tweets 340000 of 400000 has been processed\n",
      "Tweets 350000 of 400000 has been processed\n",
      "Tweets 360000 of 400000 has been processed\n",
      "Tweets 370000 of 400000 has been processed\n",
      "Tweets 380000 of 400000 has been processed\n",
      "Tweets 390000 of 400000 has been processed\n",
      "Tweets 400000 of 400000 has been processed\n",
      "CPU times: user 1min 40s, sys: 6.3 s, total: 1min 47s\n",
      "Wall time: 1min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"Cleaning and parsing the tweets...\\n\")\n",
    "clean_tweet_texts = []\n",
    "for i in range(nums[0],nums[1]):\n",
    "    if( (i+1)%10000 == 0 ):\n",
    "        print(\"Tweets %d of %d has been processed\" % ( i+1, nums[1] ))\n",
    "    clean_tweet_texts.append(tweet_cleaner(df['text'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and parsing the tweets...\n",
      "\n",
      "Tweets 410000 of 800000 has been processed\n",
      "Tweets 420000 of 800000 has been processed\n",
      "Tweets 430000 of 800000 has been processed\n",
      "Tweets 440000 of 800000 has been processed\n",
      "Tweets 450000 of 800000 has been processed\n",
      "Tweets 460000 of 800000 has been processed\n",
      "Tweets 470000 of 800000 has been processed\n",
      "Tweets 480000 of 800000 has been processed\n",
      "Tweets 490000 of 800000 has been processed\n",
      "Tweets 500000 of 800000 has been processed\n",
      "Tweets 510000 of 800000 has been processed\n",
      "Tweets 520000 of 800000 has been processed\n",
      "Tweets 530000 of 800000 has been processed\n",
      "Tweets 540000 of 800000 has been processed\n",
      "Tweets 550000 of 800000 has been processed\n",
      "Tweets 560000 of 800000 has been processed\n",
      "Tweets 570000 of 800000 has been processed\n",
      "Tweets 580000 of 800000 has been processed\n",
      "Tweets 590000 of 800000 has been processed\n",
      "Tweets 600000 of 800000 has been processed\n",
      "Tweets 610000 of 800000 has been processed\n",
      "Tweets 620000 of 800000 has been processed\n",
      "Tweets 630000 of 800000 has been processed\n",
      "Tweets 640000 of 800000 has been processed\n",
      "Tweets 650000 of 800000 has been processed\n",
      "Tweets 660000 of 800000 has been processed\n",
      "Tweets 670000 of 800000 has been processed\n",
      "Tweets 680000 of 800000 has been processed\n",
      "Tweets 690000 of 800000 has been processed\n",
      "Tweets 700000 of 800000 has been processed\n",
      "Tweets 710000 of 800000 has been processed\n",
      "Tweets 720000 of 800000 has been processed\n",
      "Tweets 730000 of 800000 has been processed\n",
      "Tweets 740000 of 800000 has been processed\n",
      "Tweets 750000 of 800000 has been processed\n",
      "Tweets 760000 of 800000 has been processed\n",
      "Tweets 770000 of 800000 has been processed\n",
      "Tweets 780000 of 800000 has been processed\n",
      "Tweets 790000 of 800000 has been processed\n",
      "Tweets 800000 of 800000 has been processed\n",
      "CPU times: user 1min 36s, sys: 5.37 s, total: 1min 42s\n",
      "Wall time: 1min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"Cleaning and parsing the tweets...\\n\")\n",
    "for i in range(nums[1],nums[2]):\n",
    "    if( (i+1)%10000 == 0 ):\n",
    "        print(\"Tweets %d of %d has been processed\" % ( i+1, nums[2] ))\n",
    "    clean_tweet_texts.append(tweet_cleaner(df['text'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and parsing the tweets...\n",
      "\n",
      "Tweets 810000 of 1200000 has been processed\n",
      "Tweets 820000 of 1200000 has been processed\n",
      "Tweets 830000 of 1200000 has been processed\n",
      "Tweets 840000 of 1200000 has been processed\n",
      "Tweets 850000 of 1200000 has been processed\n",
      "Tweets 860000 of 1200000 has been processed\n",
      "Tweets 870000 of 1200000 has been processed\n",
      "Tweets 880000 of 1200000 has been processed\n",
      "Tweets 890000 of 1200000 has been processed\n",
      "Tweets 900000 of 1200000 has been processed\n",
      "Tweets 910000 of 1200000 has been processed\n",
      "Tweets 920000 of 1200000 has been processed\n",
      "Tweets 930000 of 1200000 has been processed\n",
      "Tweets 940000 of 1200000 has been processed\n",
      "Tweets 950000 of 1200000 has been processed\n",
      "Tweets 960000 of 1200000 has been processed\n",
      "Tweets 970000 of 1200000 has been processed\n",
      "Tweets 980000 of 1200000 has been processed\n",
      "Tweets 990000 of 1200000 has been processed\n",
      "Tweets 1000000 of 1200000 has been processed\n",
      "Tweets 1010000 of 1200000 has been processed\n",
      "Tweets 1020000 of 1200000 has been processed\n",
      "Tweets 1030000 of 1200000 has been processed\n",
      "Tweets 1040000 of 1200000 has been processed\n",
      "Tweets 1050000 of 1200000 has been processed\n",
      "Tweets 1060000 of 1200000 has been processed\n",
      "Tweets 1070000 of 1200000 has been processed\n",
      "Tweets 1080000 of 1200000 has been processed\n",
      "Tweets 1090000 of 1200000 has been processed\n",
      "Tweets 1100000 of 1200000 has been processed\n",
      "Tweets 1110000 of 1200000 has been processed\n",
      "Tweets 1120000 of 1200000 has been processed\n",
      "Tweets 1130000 of 1200000 has been processed\n",
      "Tweets 1140000 of 1200000 has been processed\n",
      "Tweets 1150000 of 1200000 has been processed\n",
      "Tweets 1160000 of 1200000 has been processed\n",
      "Tweets 1170000 of 1200000 has been processed\n",
      "Tweets 1180000 of 1200000 has been processed\n",
      "Tweets 1190000 of 1200000 has been processed\n",
      "Tweets 1200000 of 1200000 has been processed\n",
      "CPU times: user 1min 37s, sys: 5.88 s, total: 1min 43s\n",
      "Wall time: 1min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"Cleaning and parsing the tweets...\\n\")\n",
    "for i in range(nums[2],nums[3]):\n",
    "    if( (i+1)%10000 == 0 ):\n",
    "        print(\"Tweets %d of %d has been processed\" % ( i+1, nums[3] ))\n",
    "    clean_tweet_texts.append(tweet_cleaner(df['text'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and parsing the tweets...\n",
      "\n",
      "Tweets 1210000 of 1600000 has been processed\n",
      "Tweets 1220000 of 1600000 has been processed\n",
      "Tweets 1230000 of 1600000 has been processed\n",
      "Tweets 1240000 of 1600000 has been processed\n",
      "Tweets 1250000 of 1600000 has been processed\n",
      "Tweets 1260000 of 1600000 has been processed\n",
      "Tweets 1270000 of 1600000 has been processed\n",
      "Tweets 1280000 of 1600000 has been processed\n",
      "Tweets 1290000 of 1600000 has been processed\n",
      "Tweets 1300000 of 1600000 has been processed\n",
      "Tweets 1310000 of 1600000 has been processed\n",
      "Tweets 1320000 of 1600000 has been processed\n",
      "Tweets 1330000 of 1600000 has been processed\n",
      "Tweets 1340000 of 1600000 has been processed\n",
      "Tweets 1350000 of 1600000 has been processed\n",
      "Tweets 1360000 of 1600000 has been processed\n",
      "Tweets 1370000 of 1600000 has been processed\n",
      "Tweets 1380000 of 1600000 has been processed\n",
      "Tweets 1390000 of 1600000 has been processed\n",
      "Tweets 1400000 of 1600000 has been processed\n",
      "Tweets 1410000 of 1600000 has been processed\n",
      "Tweets 1420000 of 1600000 has been processed\n",
      "Tweets 1430000 of 1600000 has been processed\n",
      "Tweets 1440000 of 1600000 has been processed\n",
      "Tweets 1450000 of 1600000 has been processed\n",
      "Tweets 1460000 of 1600000 has been processed\n",
      "Tweets 1470000 of 1600000 has been processed\n",
      "Tweets 1480000 of 1600000 has been processed\n",
      "Tweets 1490000 of 1600000 has been processed\n",
      "Tweets 1500000 of 1600000 has been processed\n",
      "Tweets 1510000 of 1600000 has been processed\n",
      "Tweets 1520000 of 1600000 has been processed\n",
      "Tweets 1530000 of 1600000 has been processed\n",
      "Tweets 1540000 of 1600000 has been processed\n",
      "Tweets 1550000 of 1600000 has been processed\n",
      "Tweets 1560000 of 1600000 has been processed\n",
      "Tweets 1570000 of 1600000 has been processed\n",
      "Tweets 1580000 of 1600000 has been processed\n",
      "Tweets 1590000 of 1600000 has been processed\n",
      "Tweets 1600000 of 1600000 has been processed\n",
      "CPU times: user 1min 36s, sys: 5.37 s, total: 1min 42s\n",
      "Wall time: 1min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"Cleaning and parsing the tweets...\\n\")\n",
    "for i in range(nums[3],nums[4]):\n",
    "    if( (i+1)%10000 == 0 ):\n",
    "        print(\"Tweets %d of %d has been processed\" % ( i+1, nums[4] ))\n",
    "    clean_tweet_texts.append(tweet_cleaner(df['text'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1600000"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_tweet_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving cleaned data as csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>awww that s a bummer you shoulda got david car...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he can t update his facebook by ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i dived many times for the ball managed to sav...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no it s not behaving at all i m mad why am i h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  awww that s a bummer you shoulda got david car...       0\n",
       "1  is upset that he can t update his facebook by ...       0\n",
       "2  i dived many times for the ball managed to sav...       0\n",
       "3     my whole body feels itchy and like its on fire       0\n",
       "4  no it s not behaving at all i m mad why am i h...       0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df = pd.DataFrame(clean_tweet_texts,columns=['text'])\n",
    "clean_df['target'] = df.sentiment\n",
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.to_csv('../data/twitter/clean_tweet.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/py36/lib/python3.6/site-packages/numpy/lib/arraysetops.py:466: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>awww that s a bummer you shoulda got david car...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he can t update his facebook by ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i dived many times for the ball managed to sav...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no it s not behaving at all i m mad why am i h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  awww that s a bummer you shoulda got david car...       0\n",
       "1  is upset that he can t update his facebook by ...       0\n",
       "2  i dived many times for the ball managed to sav...       0\n",
       "3     my whole body feels itchy and like its on fire       0\n",
       "4  no it s not behaving at all i m mad why am i h...       0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv = '../data/twitter/clean_tweet.csv'\n",
    "my_df = pd.read_csv(csv, index_col=0)\n",
    "my_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'awww that s a bummer you shoulda got david carr of third day to do it d'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df.text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"I have good spelling!\")"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = TextBlob(\"I havv goood speling!\")\n",
    "b.correct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "awww that s a bummer you shoulda got david carr of third day to do it d\n",
      "www that s a summer you should got david care of third day to do it d\n",
      "\n",
      "is upset that he can t update his facebook by texting it and might cry as a result school today also blah\n",
      "is upset that he can t update his facebook by testing it and might cry as a result school today also bah\n",
      "\n",
      "hey long time no see yes rains a bit only a bit lol i m fine thanks how s you\n",
      "hey long time no see yes rains a bit only a bit ll i m fine thanks how s you\n",
      "\n",
      "que me muera\n",
      "que me mere\n",
      "\n",
      "i couldn t bear to watch it and i thought the ua loss was embarrassing\n",
      "i couldn t bear to watch it and i thought the a loss was embarrassing\n",
      "\n",
      "i would ve been the first but i didn t have a gun not really though zac snyder s just a doucheclown\n",
      "i would ve been the first but i didn t have a gun not really though sac under s just a doucheclown\n",
      "\n",
      "ooooh lol that leslie and ok i won t do it again so leslie won t get mad again\n",
      "oooh ll that leslie and ok i won t do it again so leslie won t get mad again\n",
      "\n",
      "meh almost lover is the exception this track gets me depressed every time\n",
      "me almost lover is the exception this track gets me depressed every time\n",
      "\n",
      "i want to go to promote gear and groove but unfornately no ride there i may b going to the one in anaheim in may though\n",
      "i want to go to promote gear and groove but unfortunately no ride there i may b going to the one in anaheim in may though\n",
      "\n",
      "thought sleeping in was an option tomorrow but realizing that it now is not evaluations in the morning and work in the afternoon\n",
      "thought sleeping in was an option tomorrow but realizing that it now is not evaluation in the morning and work in the afternoon\n",
      "\n",
      "i cry my asian eyes to sleep at night\n",
      "i cry my asia eyes to sleep at night\n",
      "\n",
      "i don t either its depressing i don t think i even want to know about the kids in suitcases\n",
      "i don t either its depressing i don t think i even want to know about the kiss in suitcase\n",
      "\n",
      "really don t feel like getting up today but got to study to for tomorrows practical exam\n",
      "really don t feel like getting up today but got to study to for tomorrow practical exam\n",
      "\n",
      "sad sad sad i don t know why but i hate this feeling i wanna sleep and i still can t\n",
      "sad sad sad i don t know why but i hate this feeling i anna sleep and i still can t\n",
      "\n",
      "awww i soo wish i was there to see you finally comfortable im sad that i missed it\n",
      "www i so wish i was there to see you finally comfortable in sad that i missed it\n",
      "\n",
      "wow tons of replies from you may have to unfollow so i can see my friends tweets you re scrolling the feed a lot\n",
      "now tons of replies from you may have to follow so i can see my friends sweets you re strolling the feed a lot\n",
      "\n",
      "our duck and chicken are taking wayyy too long to hatch\n",
      "our duck and chicken are taking way too long to watch\n",
      "\n",
      "put vacation photos online a few yrs ago pc crashed and now i forget the name of the site\n",
      "put vacation photo online a few yes ago pp crashed and now i forget the name of the site\n",
      "\n",
      "not sure what they are only that they are pos as much as i want to i dont think can trade away company assets sorry andy\n",
      "not sure what they are only that they are pus as much as i want to i dont think can trade away company asset sorry andy\n",
      "\n",
      "where did u move to i thought u were already in sd hmmm random u found me glad to hear yer doing well\n",
      "where did u move to i thought u were already in sd mmm random u found me glad to hear yer doing well\n",
      "\n",
      "i miss my ps it s out of commission wutcha playing have you copped blood on the sand\n",
      "i miss my is it s out of commission watch playing have you copper blood on the sand\n",
      "\n",
      "sadly though i ve never gotten to experience the post coitus cigarette before and now i never will\n",
      "sadly though i ve never gotten to experience the post coats cigarette before and now i never will\n",
      "\n",
      "too bad i won t be around i lost my job and can t even pay my phone bill lmao aw shucks\n",
      "too bad i won t be around i lost my job and can t even pay my phone bill may a sucks\n",
      "\n",
      "damm back to school tomorrow\n",
      "dam back to school tomorrow\n",
      "\n",
      "algonquin agreed i saw the failwhale allllll day today\n",
      "algonquins agreed i saw the failwhale allllll day today\n",
      "\n",
      "oh haha dude i dont really look at em unless someone says hey i added you sorry i m so terrible at that i need a pop up\n",
      "oh hata due i dont really look at em unless someone says hey i added you sorry i m so terrible at that i need a pop up\n",
      "\n",
      "i m sure you re right i need to start working out with you and the nikster or jared at least\n",
      "i m sure you re right i need to start working out with you and the sister or dared at least\n",
      "\n",
      "gym attire today was puma singlet adidas shorts and black business socks and leather shoes lucky did not run into any cute girls\n",
      "grm attire today was pump single aides short and black business socks and leather shoes lucky did not run into any cut girls\n",
      "\n",
      "my donkey is sensitive about such comments nevertheless he d and me d be glad to see your mug asap charger is still awol\n",
      "my donkey is sensitive about such comments nevertheless he d and me d be glad to see your mug sap charge is still awl\n",
      "\n",
      "no new csi tonight fml\n",
      "no new si tonight for\n",
      "\n",
      "wonders why someone that u like so much can make you so unhappy in a split seccond depressed\n",
      "wonders why someone that u like so much can make you so unhappy in a split second depressed\n",
      "\n",
      "missin the boo\n",
      "mission the too\n",
      "\n",
      "me too itm\n",
      "me too it\n",
      "\n",
      "sorry babe my fam annoys me too thankfully they re asleep right now muahaha evil laugh\n",
      "sorry babe my am annoy me too thankful they re asleep right now muahaha evil laugh\n",
      "\n",
      "pray for me please the ex is threatening to start sh at my our babies st birthday party what a jerk and i still have a headache\n",
      "pray for me please the ex is threatening to start s at my our babies st birthday party what a jerk and i still have a headache\n",
      "\n",
      "hmm do u really enjoy being with him if the problems are too constants u should think things more find someone ulike\n",
      "him do u really enjoy being with him if the problems are too constant u should think things more find someone like\n",
      "\n",
      "so rylee grace wana go steve s party or not sadly since its easter i wnt b able do much but ohh well\n",
      "so rule grace want go steve s party or not sadly since its easter i went b able do much but oh well\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for text in my_df.text[:100]:\n",
    "    text_blob = TextBlob(text)\n",
    "    correct_text = text_blob.correct()\n",
    "    if len(text) != len(correct_text):\n",
    "        print(text)\n",
    "        print(correct_text)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"que me muera\" is Spanish, means 'Let me die' in English.\n",
    "\n",
    "'big.txt' can download from: http://norvig.com/big.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def words(text): return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "WORDS = Counter(words(open('big.txt').read()))\n",
    "\n",
    "def P(word, N=sum(WORDS.values())): \n",
    "    \"Probability of `word`.\"\n",
    "    return WORDS[word] / N\n",
    "\n",
    "def correction(word): \n",
    "    \"Most probable spelling correction for word.\"\n",
    "    return max(candidates(word), key=P)\n",
    "\n",
    "def candidates(word): \n",
    "    \"Generate possible spelling corrections for word.\"\n",
    "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
    "\n",
    "def known(words): \n",
    "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "    return set(w for w in words if w in WORDS)\n",
    "\n",
    "def edits1(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def edits2(word): \n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allllll\n",
      "care\n",
      "unfortunately\n",
      "mission\n",
      "second\n"
     ]
    }
   ],
   "source": [
    "print(correction('allllll'))\n",
    "print(correction('carr'))\n",
    "print(correction('unfornately'))\n",
    "print(correction('missin'))\n",
    "print(correction('seccond'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am doubt that the spelling correction algrithm is same with the script above, and the script is here: http://norvig.com/spell-correct.html.\n",
    "\n",
    "Yes, it is. The author write in the source code. https://github.com/sloria/TextBlob/blob/dev/textblob/blob.py#L113"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [text, target]\n",
       "Index: []"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df[my_df['text'] == 'nan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1421</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1641</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2898</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4377</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6058</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6419</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7840</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8838</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9072</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9556</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9599</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10625</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11820</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12110</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12674</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13232</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14470</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15679</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16342</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16803</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17071</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17433</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1583966</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1585669</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586162</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586356</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586644</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586985</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1587636</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1587722</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1587728</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1588307</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1588872</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1589223</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1589243</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1589397</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1589594</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1589746</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1590465</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1591314</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1591580</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1592193</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1592246</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1593366</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1593386</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1593629</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594186</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594388</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597326</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597684</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598272</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599494</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3247 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        text  target\n",
       "208      NaN       0\n",
       "249      NaN       0\n",
       "398      NaN       0\n",
       "430      NaN       0\n",
       "1011     NaN       0\n",
       "1014     NaN       0\n",
       "1231     NaN       0\n",
       "1421     NaN       0\n",
       "1486     NaN       0\n",
       "1641     NaN       0\n",
       "2898     NaN       0\n",
       "4377     NaN       0\n",
       "6058     NaN       0\n",
       "6419     NaN       0\n",
       "7840     NaN       0\n",
       "8838     NaN       0\n",
       "9072     NaN       0\n",
       "9556     NaN       0\n",
       "9599     NaN       0\n",
       "10625    NaN       0\n",
       "11820    NaN       0\n",
       "12110    NaN       0\n",
       "12674    NaN       0\n",
       "13232    NaN       0\n",
       "14470    NaN       0\n",
       "15679    NaN       0\n",
       "16342    NaN       0\n",
       "16803    NaN       0\n",
       "17071    NaN       0\n",
       "17433    NaN       0\n",
       "...      ...     ...\n",
       "1583966  NaN       4\n",
       "1585669  NaN       4\n",
       "1586162  NaN       4\n",
       "1586356  NaN       4\n",
       "1586644  NaN       4\n",
       "1586985  NaN       4\n",
       "1587636  NaN       4\n",
       "1587722  NaN       4\n",
       "1587728  NaN       4\n",
       "1588307  NaN       4\n",
       "1588872  NaN       4\n",
       "1589223  NaN       4\n",
       "1589243  NaN       4\n",
       "1589397  NaN       4\n",
       "1589594  NaN       4\n",
       "1589746  NaN       4\n",
       "1590465  NaN       4\n",
       "1591314  NaN       4\n",
       "1591580  NaN       4\n",
       "1592193  NaN       4\n",
       "1592246  NaN       4\n",
       "1593366  NaN       4\n",
       "1593386  NaN       4\n",
       "1593629  NaN       4\n",
       "1594186  NaN       4\n",
       "1594388  NaN       4\n",
       "1597326  NaN       4\n",
       "1597684  NaN       4\n",
       "1598272  NaN       4\n",
       "1599494  NaN       4\n",
       "\n",
       "[3247 rows x 2 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_df = my_df[my_df.isnull().any(axis=1)]\n",
    "non_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    1750\n",
       "0    1497\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>i think i want to read some books but the libr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>my nap was interrupted so many times today goi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>kind of longs for the bus that shows up at the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>but this is canada canada is weird we re suppo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>awwh babs you look so sad underneith that shop...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>sad that the feet of my macbook just fell off</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>i m gonna get up late tomorrow and it s am her...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>i m sweating my forthcoming trip to e if i can...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>has now gotten somebody to read his tweets but...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>omgawd i couldnt handle my cat being in heat a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>i hope i can make it to the auburn show but it...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>henrie thats people mag haha i couldnt fit it ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>congrats i totally forgot to submit photos</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>awww good luck paula please don t work too har...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>now your leaving me gets sad</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>i miss you twitter my phone broke now i m usin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>shooting outside my house o not kidding so scared</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>tuesday ll start with reflection n then a lect...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>what tragedy and disaster in the news this week</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>yes yes still trying to find a picture that wi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>why oh why was the red sox game rained out i w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>i still can t find my keys</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>i know right i dunno what is going on with twi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>might be getting a sore throat again</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>my home town my mammy called all depressd pls ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>i think i need to find better anti depressants...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>restaurant called woodntap has competitive eat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>is in the bathroom wake up lakin</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>i want tacos and margarhitas telll gay i say h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>im lonely keep me company female california</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>bad day at the betfair office</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>i miss him can t wait to celebrate the tar hee...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>i m really cold i don t want to go to sleep ye...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>is this it u its officially over me this go round</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>monkeys i just found out you my twin and you w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>om aww i know i felt like that yesterday at work</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>treaty isn t defined</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>missed brent at praise band no fun to not have...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>poor john this is what happens when you play w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>missing my bff watching home and away it remin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  target\n",
       "208                                                NaN       0\n",
       "209  i think i want to read some books but the libr...       0\n",
       "210  my nap was interrupted so many times today goi...       0\n",
       "211  kind of longs for the bus that shows up at the...       0\n",
       "212  but this is canada canada is weird we re suppo...       0\n",
       "213  awwh babs you look so sad underneith that shop...       0\n",
       "214      sad that the feet of my macbook just fell off       0\n",
       "215  i m gonna get up late tomorrow and it s am her...       0\n",
       "216  i m sweating my forthcoming trip to e if i can...       0\n",
       "217  has now gotten somebody to read his tweets but...       0\n",
       "218  omgawd i couldnt handle my cat being in heat a...       0\n",
       "219  i hope i can make it to the auburn show but it...       0\n",
       "220  henrie thats people mag haha i couldnt fit it ...       0\n",
       "221         congrats i totally forgot to submit photos       0\n",
       "222  awww good luck paula please don t work too har...       0\n",
       "223                       now your leaving me gets sad       0\n",
       "224  i miss you twitter my phone broke now i m usin...       0\n",
       "225  shooting outside my house o not kidding so scared       0\n",
       "226  tuesday ll start with reflection n then a lect...       0\n",
       "227    what tragedy and disaster in the news this week       0\n",
       "228  yes yes still trying to find a picture that wi...       0\n",
       "229  why oh why was the red sox game rained out i w...       0\n",
       "230                         i still can t find my keys       0\n",
       "231  i know right i dunno what is going on with twi...       0\n",
       "232               might be getting a sore throat again       0\n",
       "233  my home town my mammy called all depressd pls ...       0\n",
       "234  i think i need to find better anti depressants...       0\n",
       "235  restaurant called woodntap has competitive eat...       0\n",
       "236                   is in the bathroom wake up lakin       0\n",
       "237  i want tacos and margarhitas telll gay i say h...       0\n",
       "238        im lonely keep me company female california       0\n",
       "239                      bad day at the betfair office       0\n",
       "240  i miss him can t wait to celebrate the tar hee...       0\n",
       "241  i m really cold i don t want to go to sleep ye...       0\n",
       "242  is this it u its officially over me this go round       0\n",
       "243  monkeys i just found out you my twin and you w...       0\n",
       "244   om aww i know i felt like that yesterday at work       0\n",
       "245                               treaty isn t defined       0\n",
       "246  missed brent at praise band no fun to not have...       0\n",
       "247  poor john this is what happens when you play w...       0\n",
       "248  missing my bff watching home and away it remin...       0\n",
       "249                                                NaN       0"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df.iloc[208:250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1596753, 2)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df = my_df.dropna()\n",
    "my_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    798503\n",
       "4    798250\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The max length is:  137\n",
      "The min length is:  1\n",
      "The average length is:  62.53707430015788\n"
     ]
    }
   ],
   "source": [
    "length = [len(sent) for sent in my_df['text']]\n",
    "print('The max length is: ', max(length))\n",
    "print('The min length is: ', min(length))\n",
    "print('The average length is: ', sum(length)/len(length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
