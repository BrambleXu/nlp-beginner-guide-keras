{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    }
   ],
   "source": [
    "import data_helpers\n",
    "\n",
    "#==================Preprocess===================\n",
    "\n",
    "# Load data\n",
    "positive_data_file = \"../data/rt-polaritydata/rt-polarity.pos\"\n",
    "negtive_data_file = \"../data/rt-polaritydata/rt-polarity.neg\"\n",
    "\n",
    "# Load data\n",
    "print(\"Loading data...\")\n",
    "x_text, y = data_helpers.load_data_and_labels(positive_data_file, negtive_data_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"the rock is destined to be the 21st century 's new conan and that he 's going to make a splash even greater than arnold schwarzenegger , jean claud van damme or steven segal\",\n",
       " \"the gorgeously elaborate continuation of the lord of the rings trilogy is so huge that a column of words cannot adequately describe co writer director peter jackson 's expanded vision of j r r tolkien 's middle earth\"]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_text[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Tokenize, Pad, Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================Convert string to index================\n",
    "# Tokenizer\n",
    "tk = Tokenizer(num_words=None, char_level=True, oov_token='UNK')\n",
    "tk.fit_on_texts(x_text)\n",
    "# If we already have a character list, then replace the tk.word_index\n",
    "# If not, just skip below part\n",
    "\n",
    "# -----------------------Skip part start--------------------------\n",
    "# construct a new vocabulary\n",
    "alphabet = \"abcdefghijklmnopqrstuvwxyz0123456789 ,;.!?:'\\\"/\\\\|_@#$%^&*~`+-=<>()[]{}\"\n",
    "char_dict = {}\n",
    "for i, char in enumerate(alphabet):\n",
    "    char_dict[char] = i + 1\n",
    "\n",
    "# Use char_dict to replace the tk.word_index\n",
    "tk.word_index = char_dict.copy()\n",
    "# Add 'UNK' to the vocabulary\n",
    "tk.word_index[tk.oov_token] = max(char_dict.values()) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tk.word_index) # 69 char, and 1 UNK token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 37,\n",
       " '!': 41,\n",
       " '\"': 45,\n",
       " '#': 51,\n",
       " '$': 52,\n",
       " '%': 53,\n",
       " '&': 55,\n",
       " \"'\": 44,\n",
       " '(': 64,\n",
       " ')': 65,\n",
       " '*': 56,\n",
       " '+': 59,\n",
       " ',': 38,\n",
       " '-': 60,\n",
       " '.': 40,\n",
       " '/': 46,\n",
       " '0': 27,\n",
       " '1': 28,\n",
       " '2': 29,\n",
       " '3': 30,\n",
       " '4': 31,\n",
       " '5': 32,\n",
       " '6': 33,\n",
       " '7': 34,\n",
       " '8': 35,\n",
       " '9': 36,\n",
       " ':': 43,\n",
       " ';': 39,\n",
       " '<': 62,\n",
       " '=': 61,\n",
       " '>': 63,\n",
       " '?': 42,\n",
       " '@': 50,\n",
       " 'UNK': 70,\n",
       " '[': 66,\n",
       " '\\\\': 47,\n",
       " ']': 67,\n",
       " '^': 54,\n",
       " '_': 49,\n",
       " '`': 58,\n",
       " 'a': 1,\n",
       " 'b': 2,\n",
       " 'c': 3,\n",
       " 'd': 4,\n",
       " 'e': 5,\n",
       " 'f': 6,\n",
       " 'g': 7,\n",
       " 'h': 8,\n",
       " 'i': 9,\n",
       " 'j': 10,\n",
       " 'k': 11,\n",
       " 'l': 12,\n",
       " 'm': 13,\n",
       " 'n': 14,\n",
       " 'o': 15,\n",
       " 'p': 16,\n",
       " 'q': 17,\n",
       " 'r': 18,\n",
       " 's': 19,\n",
       " 't': 20,\n",
       " 'u': 21,\n",
       " 'v': 22,\n",
       " 'w': 23,\n",
       " 'x': 24,\n",
       " 'y': 25,\n",
       " 'z': 26,\n",
       " '{': 68,\n",
       " '|': 48,\n",
       " '}': 69,\n",
       " '~': 57}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string to index\n",
    "sequences = tk.texts_to_sequences(x_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20, 8, 5, 37, 18, 15, 3, 11, 37, 9, 19, 37, 4, 5, 19, 20, 9, 14, 5, 4, 37, 20, 15, 37, 2, 5, 37, 20, 8, 5, 37, 29, 28, 19, 20, 37, 3, 5, 14, 20, 21, 18, 25, 37, 44, 19, 37, 14, 5, 23, 37, 3, 15, 14, 1, 14, 37, 1, 14, 4, 37, 20, 8, 1, 20, 37, 8, 5, 37, 44, 19, 37, 7, 15, 9, 14, 7, 37, 20, 15, 37, 13, 1, 11, 5, 37, 1, 37, 19, 16, 12, 1, 19, 8, 37, 5, 22, 5, 14, 37, 7, 18, 5, 1, 20, 5, 18, 37, 20, 8, 1, 14, 37, 1, 18, 14, 15, 12, 4, 37, 19, 3, 8, 23, 1, 18, 26, 5, 14, 5, 7, 7, 5, 18, 37, 38, 37, 10, 5, 1, 14, 37, 3, 12, 1, 21, 4, 37, 22, 1, 14, 37, 4, 1, 13, 13, 5, 37, 15, 18, 37, 19, 20, 5, 22, 5, 14, 37, 19, 5, 7, 1, 12], [20, 8, 5, 37, 7, 15, 18, 7, 5, 15, 21, 19, 12, 25, 37, 5, 12, 1, 2, 15, 18, 1, 20, 5, 37, 3, 15, 14, 20, 9, 14, 21, 1, 20, 9, 15, 14, 37, 15, 6, 37, 20, 8, 5, 37, 12, 15, 18, 4, 37, 15, 6, 37, 20, 8, 5, 37, 18, 9, 14, 7, 19, 37, 20, 18, 9, 12, 15, 7, 25, 37, 9, 19, 37, 19, 15, 37, 8, 21, 7, 5, 37, 20, 8, 1, 20, 37, 1, 37, 3, 15, 12, 21, 13, 14, 37, 15, 6, 37, 23, 15, 18, 4, 19, 37, 3, 1, 14, 14, 15, 20, 37, 1, 4, 5, 17, 21, 1, 20, 5, 12, 25, 37, 4, 5, 19, 3, 18, 9, 2, 5, 37, 3, 15, 37, 23, 18, 9, 20, 5, 18, 37, 4, 9, 18, 5, 3, 20, 15, 18, 37, 16, 5, 20, 5, 18, 37, 10, 1, 3, 11, 19, 15, 14, 37, 44, 19, 37, 5, 24, 16, 1, 14, 4, 5, 4, 37, 22, 9, 19, 9, 15, 14, 37, 15, 6, 37, 10, 37, 18, 37, 18, 37, 20, 15, 12, 11, 9, 5, 14, 37, 44, 19, 37, 13, 9, 4, 4, 12, 5, 37, 5, 1, 18, 20, 8]]\n"
     ]
    }
   ],
   "source": [
    "print(sequences[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The max length is:  266\n",
      "The min length is:  2\n",
      "The average length is:  111.5871318701932\n"
     ]
    }
   ],
   "source": [
    "# See char level length\n",
    "length = [len(sent) for sent in sequences]\n",
    "print('The max length is: ', max(length))\n",
    "print('The min length is: ', min(length))\n",
    "print('The average length is: ', sum(length)/len(length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The whole data size is:  (10662, 266)\n"
     ]
    }
   ],
   "source": [
    "# Padding\n",
    "sequences_pad = pad_sequences(sequences, maxlen=266, padding='post')\n",
    "print(\"The whole data size is: \", sequences_pad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[20,  8,  5, 37, 18, 15,  3, 11, 37,  9, 19, 37,  4,  5, 19, 20,\n",
       "         9, 14,  5,  4, 37, 20, 15, 37,  2,  5, 37, 20,  8,  5, 37, 29,\n",
       "        28, 19, 20, 37,  3,  5, 14, 20, 21, 18, 25, 37, 44, 19, 37, 14,\n",
       "         5, 23, 37,  3, 15, 14,  1, 14, 37,  1, 14,  4, 37, 20,  8,  1,\n",
       "        20, 37,  8,  5, 37, 44, 19, 37,  7, 15,  9, 14,  7, 37, 20, 15,\n",
       "        37, 13,  1, 11,  5, 37,  1, 37, 19, 16, 12,  1, 19,  8, 37,  5,\n",
       "        22,  5, 14, 37,  7, 18,  5,  1, 20,  5, 18, 37, 20,  8,  1, 14,\n",
       "        37,  1, 18, 14, 15, 12,  4, 37, 19,  3,  8, 23,  1, 18, 26,  5,\n",
       "        14,  5,  7,  7,  5, 18, 37, 38, 37, 10,  5,  1, 14, 37,  3, 12,\n",
       "         1, 21,  4, 37, 22,  1, 14, 37,  4,  1, 13, 13,  5, 37, 15, 18,\n",
       "        37, 19, 20,  5, 22,  5, 14, 37, 19,  5,  7,  1, 12,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [20,  8,  5, 37,  7, 15, 18,  7,  5, 15, 21, 19, 12, 25, 37,  5,\n",
       "        12,  1,  2, 15, 18,  1, 20,  5, 37,  3, 15, 14, 20,  9, 14, 21,\n",
       "         1, 20,  9, 15, 14, 37, 15,  6, 37, 20,  8,  5, 37, 12, 15, 18,\n",
       "         4, 37, 15,  6, 37, 20,  8,  5, 37, 18,  9, 14,  7, 19, 37, 20,\n",
       "        18,  9, 12, 15,  7, 25, 37,  9, 19, 37, 19, 15, 37,  8, 21,  7,\n",
       "         5, 37, 20,  8,  1, 20, 37,  1, 37,  3, 15, 12, 21, 13, 14, 37,\n",
       "        15,  6, 37, 23, 15, 18,  4, 19, 37,  3,  1, 14, 14, 15, 20, 37,\n",
       "         1,  4,  5, 17, 21,  1, 20,  5, 12, 25, 37,  4,  5, 19,  3, 18,\n",
       "         9,  2,  5, 37,  3, 15, 37, 23, 18,  9, 20,  5, 18, 37,  4,  9,\n",
       "        18,  5,  3, 20, 15, 18, 37, 16,  5, 20,  5, 18, 37, 10,  1,  3,\n",
       "        11, 19, 15, 14, 37, 44, 19, 37,  5, 24, 16,  1, 14,  4,  5,  4,\n",
       "        37, 22,  9, 19,  9, 15, 14, 37, 15,  6, 37, 10, 37, 18, 37, 18,\n",
       "        37, 20, 15, 12, 11,  9,  5, 14, 37, 44, 19, 37, 13,  9,  4,  4,\n",
       "        12,  5, 37,  5,  1, 18, 20,  8,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0]], dtype=int32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences_pad[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size is:  (9595, 266)\n",
      "Validation data size is:  (1067, 266)\n"
     ]
    }
   ],
   "source": [
    "# Shuffle data\n",
    "np.random.seed(42)\n",
    "shuffle_indices = np.random.permutation(np.arange(len(y)))\n",
    "x_shuffled = sequences_pad[shuffle_indices]\n",
    "y_shuffled = y[shuffle_indices]\n",
    "\n",
    "# Split train and test\n",
    "training_rate = 0.9\n",
    "train_len = int(len(y) * training_rate)\n",
    "x_train = x_shuffled[:train_len]\n",
    "y_train = y_shuffled[:train_len]\n",
    "x_test = x_shuffled[train_len:]\n",
    "y_test = y_shuffled[train_len:]\n",
    "print('Training data size is: ', x_train.shape)\n",
    "print('Validation data size is: ', x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Embedding weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(tk.word_index)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use one-hot vector, so the embedding dim is 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding weights\n",
    "embedding_dim = 70\n",
    "\n",
    "zero_vector = np.zeros((1, embedding_dim)) \n",
    "\n",
    "embedding_weights = np.concatenate((zero_vector, np.identity(vocab_size)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(71, 70)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(embedding_weights.shape)\n",
    "embedding_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding\n",
    "input_size = 266\n",
    "\n",
    "# Embedding layer Initialization\n",
    "embedding_layer = Embedding(vocab_size + 1,\n",
    "                            embedding_dim,\n",
    "                            input_length=input_size,\n",
    "                            weights=[embedding_weights])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
