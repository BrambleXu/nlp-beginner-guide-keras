{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write in train.py\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import json\n",
    "import argparse\n",
    "\n",
    "from data_utils import Data\n",
    "from models.char_cnn_zhang import CharCNNZhang\n",
    "from models.char_cnn_kim import CharCNNKim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded from ../data/ag_news_csv/train.csv\n",
      "Data loaded from ../data/ag_news_csv/test.csv\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--model', type=str, default='char_cnn_zhang', help='Specifies which model to use: char_cnn_zhang or char_cnn_kim')\n",
    "FLAGS = parser.parse_args([\"--model\", \"char_cnn_zhang\"])\n",
    "\n",
    "# Load configurations\n",
    "config = json.load(open('../config.json'))\n",
    "\n",
    "# change key from 'model' to 'char_cnn_zhang'\n",
    "model_name = config['model'] # char_cnn_zhang\n",
    "config['model'] = config[model_name]\n",
    "\n",
    "# Set the data path in order to run in the notebook \n",
    "config['data'][\"training_data_source\"] = '../data/ag_news_csv/train.csv'\n",
    "config['data'][\"validation_data_source\"] = '../data/ag_news_csv/test.csv'\n",
    "\n",
    "# Load training data\n",
    "training_data = Data(data_source=config[\"data\"][\"training_data_source\"],\n",
    "                     alphabet=config[\"data\"][\"alphabet\"],\n",
    "                     input_size=config[\"data\"][\"input_size\"],\n",
    "                     num_of_classes=config[\"data\"][\"num_of_classes\"])\n",
    "training_data.load_data()\n",
    "training_inputs, training_labels = training_data.get_all_data()\n",
    "\n",
    "# Load validation data\n",
    "validation_data = Data(data_source=config[\"data\"][\"validation_data_source\"],\n",
    "                       alphabet=config[\"data\"][\"alphabet\"],\n",
    "                       input_size=config[\"data\"][\"input_size\"],\n",
    "                       num_of_classes=config[\"data\"][\"num_of_classes\"])\n",
    "validation_data.load_data()\n",
    "validation_inputs, validation_labels = validation_data.get_all_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'char_cnn_kim': {'conv_layers': [[256, 10], [256, 7], [256, 5], [256, 3]],\n",
       "  'dropout_p': 0.1,\n",
       "  'embedding_size': 128,\n",
       "  'fully_connected_layers': [1024, 1024],\n",
       "  'loss': 'categorical_crossentropy',\n",
       "  'optimizer': 'adam',\n",
       "  'threshold': 1e-06},\n",
       " 'char_cnn_zhang': {'conv_layers': [[256, 7, 3],\n",
       "   [256, 7, 3],\n",
       "   [256, 3, -1],\n",
       "   [256, 3, -1],\n",
       "   [256, 3, -1],\n",
       "   [256, 3, 3]],\n",
       "  'dropout_p': 0.5,\n",
       "  'embedding_size': 128,\n",
       "  'fully_connected_layers': [1024, 1024],\n",
       "  'loss': 'categorical_crossentropy',\n",
       "  'optimizer': 'adam',\n",
       "  'threshold': 1e-06},\n",
       " 'data': {'alphabet': 'abcdefghijklmnopqrstuvwxyz0123456789-,;.!?:\\'\"/\\\\|_@#$%^&*~`+-=<>()[]{}',\n",
       "  'alphabet_size': 69,\n",
       "  'input_size': 1014,\n",
       "  'num_of_classes': 4,\n",
       "  'training_data_source': '../data/ag_news_csv/train.csv',\n",
       "  'validation_data_source': '../data/ag_news_csv/test.csv'},\n",
       " 'model': {'conv_layers': [[256, 7, 3],\n",
       "   [256, 7, 3],\n",
       "   [256, 3, -1],\n",
       "   [256, 3, -1],\n",
       "   [256, 3, -1],\n",
       "   [256, 3, 3]],\n",
       "  'dropout_p': 0.5,\n",
       "  'embedding_size': 128,\n",
       "  'fully_connected_layers': [1024, 1024],\n",
       "  'loss': 'categorical_crossentropy',\n",
       "  'optimizer': 'adam',\n",
       "  'threshold': 1e-06},\n",
       " 'notes': 'default',\n",
       " 'training': {'batch_size': 128,\n",
       "  'checkpoint_every': 100,\n",
       "  'epochs': 5000,\n",
       "  'evaluate_every': 100}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conv_layers': [[256, 7, 3],\n",
       "  [256, 7, 3],\n",
       "  [256, 3, -1],\n",
       "  [256, 3, -1],\n",
       "  [256, 3, -1],\n",
       "  [256, 3, 3]],\n",
       " 'dropout_p': 0.5,\n",
       " 'embedding_size': 128,\n",
       " 'fully_connected_layers': [1024, 1024],\n",
       " 'loss': 'categorical_crossentropy',\n",
       " 'optimizer': 'adam',\n",
       " 'threshold': 1e-06}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alphabet': 'abcdefghijklmnopqrstuvwxyz0123456789-,;.!?:\\'\"/\\\\|_@#$%^&*~`+-=<>()[]{}',\n",
       " 'alphabet_size': 69,\n",
       " 'input_size': 1014,\n",
       " 'num_of_classes': 4,\n",
       " 'training_data_source': '../data/ag_news_csv/train.csv',\n",
       " 'validation_data_source': '../data/ag_news_csv/test.csv'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# See the model at a glance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CharCNNZhang model built: \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sent_input (InputLayer)      (None, 1014)              0         \n",
      "_________________________________________________________________\n",
      "embedding_4 (Embedding)      (None, 1014, 128)         8960      \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 1008, 256)         229632    \n",
      "_________________________________________________________________\n",
      "thresholded_re_lu_1 (Thresho (None, 1008, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 336, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 330, 256)          459008    \n",
      "_________________________________________________________________\n",
      "thresholded_re_lu_2 (Thresho (None, 330, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 110, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 108, 256)          196864    \n",
      "_________________________________________________________________\n",
      "thresholded_re_lu_3 (Thresho (None, 108, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 106, 256)          196864    \n",
      "_________________________________________________________________\n",
      "thresholded_re_lu_4 (Thresho (None, 106, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 104, 256)          196864    \n",
      "_________________________________________________________________\n",
      "thresholded_re_lu_5 (Thresho (None, 104, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 102, 256)          196864    \n",
      "_________________________________________________________________\n",
      "thresholded_re_lu_6 (Thresho (None, 102, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 34, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8704)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              8913920   \n",
      "_________________________________________________________________\n",
      "thresholded_re_lu_7 (Thresho (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "thresholded_re_lu_8 (Thresho (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 4100      \n",
      "=================================================================\n",
      "Total params: 11,452,676\n",
      "Trainable params: 11,452,676\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = CharCNNZhang(input_size=config[\"data\"][\"input_size\"],\n",
    "                             alphabet_size=config[\"data\"][\"alphabet_size\"],\n",
    "                             embedding_size=config[\"model\"][\"embedding_size\"],\n",
    "                             conv_layers=config[\"model\"][\"conv_layers\"],\n",
    "                             fully_connected_layers=config[\"model\"][\"fully_connected_layers\"],\n",
    "                             num_of_classes=config[\"data\"][\"num_of_classes\"],\n",
    "                             threshold=config[\"model\"][\"threshold\"],\n",
    "                             dropout_p=config[\"model\"][\"dropout_p\"],\n",
    "                             optimizer=config[\"model\"][\"optimizer\"],\n",
    "                             loss=config[\"model\"][\"loss\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct layer by layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Embedding, Conv1D, Activation, MaxPooling1D, Dense, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter \n",
    "\n",
    "input_size = config['data']['input_size'] # 1014\n",
    "alphabet_size = config['data']['alphabet_size'] # 69\n",
    "embedding_size = config['model']['embedding_size'] # 128\n",
    "conv_layers=config[\"model\"][\"conv_layers\"] # [[256, 7, 3], [256, 7, 3], [256, 3, -1], [256, 3, -1], [256, 3, -1], [256, 3, 3]]\n",
    "\n",
    "fully_connected_layers=config[\"model\"][\"fully_connected_layers\"] # [1024, 1024]\n",
    "num_of_classes=config[\"data\"][\"num_of_classes\"] # 4\n",
    "threshold=config[\"model\"][\"threshold\"] # 1e-06\n",
    "dropout_p=config[\"model\"][\"dropout_p\"] # 0.5\n",
    "optimizer=config[\"model\"][\"optimizer\"] # adam\n",
    "loss=config[\"model\"][\"loss\"] # categorical_crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output variable of embedding must be same with the input of conv layer. Because in the conv for loop, every time it will start with a `Conv1D`, if we set the embeding output as `embedding`, it will casue a error. \n",
    "\n",
    "\n",
    "```\n",
    "# Embedding layer\n",
    "# the output should be the same with conv\n",
    "embedding = Embedding(alphabet_size+1, embedding_size, input_length=input_size)(inputs)\n",
    "# Conv \n",
    "for filter_num, filter_size, pooling_size in conv_layers:\n",
    "    conv = Conv1D(filter_num, filter_size)(embedding)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sent_input (InputLayer)      (None, 1014)              0         \n",
      "_________________________________________________________________\n",
      "embedding_14 (Embedding)     (None, 1014, 128)         8960      \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 1008, 256)         229632    \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 1008, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 336, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 330, 256)          459008    \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 330, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 110, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 108, 256)          196864    \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 108, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 106, 256)          196864    \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 106, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 104, 256)          196864    \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 104, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 102, 256)          196864    \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 102, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 34, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 8704)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1024)              8913920   \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 4)                 4100      \n",
      "=================================================================\n",
      "Total params: 11,452,676\n",
      "Trainable params: 11,452,676\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Uses an embedding layer, followed by a convolutional, \n",
    "max-pooling and softmax layer.\n",
    "'''\n",
    "\n",
    "\n",
    "# Input \n",
    "inputs = Input(shape=(input_size,), name='sent_input', dtype='int64')  # shape=(?, 1014)\n",
    "# Embedding layer\n",
    "conv = Embedding(alphabet_size+1, embedding_size, input_length=input_size)(inputs)\n",
    "# Conv \n",
    "for filter_num, filter_size, pooling_size in conv_layers:\n",
    "    conv = Conv1D(filter_num, filter_size)(conv) \n",
    "    conv = Activation('relu')(conv)\n",
    "    if pooling_size != -1:\n",
    "        conv = MaxPooling1D(pool_size=pooling_size)(conv) # Final shape=(None, 34, 256)\n",
    "x = Flatten()(conv) # (None, 8704)\n",
    "# Fully connected layers \n",
    "for dense_size in fully_connected_layers:\n",
    "    x = Dense(dense_size, activation='relu')(x) # dense_size == 1024\n",
    "    x = Dropout(dropout_p)(x)\n",
    "# Output Layer\n",
    "predictions = Dense(num_of_classes, activation='softmax')(x)\n",
    "# Build model\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.compile(optimizer=optimizer, loss=loss) # Adam, categorical_crossentropy\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train the model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because here I just use CPU to run the model, so I only use 1000 samples for trianing and 100 samples for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_inputs=training_inputs[:1000]\n",
    "training_labels=training_labels[:1000]\n",
    "validation_inputs=validation_inputs[:100]\n",
    "validation_labels=validation_labels[:100]\n",
    "# epochs=config[\"training\"][\"epochs\"] # 5000\n",
    "epochs =10\n",
    "batch_size=config[\"training\"][\"batch_size\"] # 128\n",
    "# checkpoint_every=config[\"training\"][\"checkpoint_every\"] # 100\n",
    "checkpoint_every = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 1.2464 - val_loss: 1.2903\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 1.2202 - val_loss: 1.2411\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 1.1885 - val_loss: 1.1975\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 1.1699 - val_loss: 1.2534\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 1.1266 - val_loss: 1.1740\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 1.0604 - val_loss: 1.1256\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 1.0009 - val_loss: 1.1574\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.9053 - val_loss: 1.2103\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.7735 - val_loss: 1.3505\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6004 - val_loss: 2.0458\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cbe073b00>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create callbacks\n",
    "from keras.callbacks import TensorBoard\n",
    "tensorboard = TensorBoard(log_dir='./logs', histogram_freq=checkpoint_every, batch_size=batch_size,\n",
    "                          write_graph=False, write_grads=True, write_images=False,\n",
    "                          embeddings_freq=checkpoint_every,\n",
    "                          embeddings_layer_names=None)\n",
    "\n",
    "# Training\n",
    "model.fit(training_inputs, training_labels,\n",
    "          validation_data=(validation_inputs, validation_labels),\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          callbacks=[tensorboard])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the sample number is too small, after 10 epochs, model overfit the data. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
